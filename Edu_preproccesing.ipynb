{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMva3If5zxyt7SHpv06IQZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kruglikle/EduText-Analyzer/blob/data/Edu_preproccesing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_raw = open(\"starlight-9.txt\", \"r\", encoding=\"utf-8\").read()"
      ],
      "metadata": {
        "id": "UlE0yAmcEwtA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk1JTywtECc7",
        "outputId": "abf20c77-ad67-4776-a858-1ab5ad14108a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages: 217 first: 1\n",
            "Starlight 9\n",
            "\n",
            "Virginia Evans — Jenny Dooley Ksenia Baranova — Victoria Kopylova Radislav Millrood\n",
            "\n",
            "Student's Book\n",
            "\n",
            "PROSVESHCHENIYE\n",
            "PUBLISHERS\n",
            "\n",
            "Express Publishing\n",
            "--- EN ---\n",
            "Starlight 9\n",
            "\n",
            "Virginia Evans — Jenny Dooley Ksenia Baranova — Victoria Kopylova Radislav Millrood\n",
            "\n",
            "Student's Book\n",
            "\n",
            "PROSVESHCHENIYE\n",
            "PUBLISHERS\n",
            "\n",
            "Express Publishing\n",
            "First 10 module marks: [(8, '1'), (9, '1'), (10, '1'), (11, '1'), (12, '1'), (13, '1'), (14, '1'), (15, '1'), (16, '1'), (17, '1')]\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# CELL 1 — PREPROCESS (MVP) [UPDATED v2: MODULE/Module + no-merge headings]\n",
        "# =========================\n",
        "\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "# Поддерживает \"----- PAGE 2 -----\" и \"===== PAGE 2 =====\"\n",
        "PAGE_RE_DEFAULT = r\"^[=\\-]{2,}\\s*PAGE\\s*(\\d+)\\s*[=\\-]{2,}$\"\n",
        "\n",
        "@dataclass\n",
        "class PageBlock:\n",
        "    page_num: int\n",
        "    text_raw: str\n",
        "    text_clean: str\n",
        "    text_en: str\n",
        "    module_id: Optional[str] = None\n",
        "\n",
        "def normalize_whitespace(s: str) -> str:\n",
        "    # MVP (2): нормализация пробелов/табов/переводов строк без потери пунктуации\n",
        "    s = (s or \"\").replace(\"\\ufeff\", \"\")\n",
        "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    s = s.replace(\"\\t\", \" \")\n",
        "    s = re.sub(r\"[ \\u00A0]+\", \" \", s)          # множественные пробелы / NBSP\n",
        "    s = re.sub(r\"[ \\u00A0]+\\n\", \"\\n\", s)       # пробелы перед \\n\n",
        "    return s.strip()\n",
        "\n",
        "def dehyphenate_linebreaks(s: str) -> str:\n",
        "    # MVP (3): inter-\\nnational -> international\n",
        "    return re.sub(r\"(?<=\\w)-\\n(?=\\w)\", \"\", s)\n",
        "\n",
        "def looks_like_new_block(line: str) -> bool:\n",
        "    # MVP (4): эвристика \"не склеивать\", если похоже на новый блок/задание/заголовок\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return True\n",
        "\n",
        "    # \"1. \" / \"2) \"\n",
        "    if re.match(r\"^\\d+[\\.\\)]\\s+\", t):\n",
        "        return True\n",
        "\n",
        "    # \"1 a) ...\" / \"12 b) ...\"\n",
        "    if re.match(r\"^\\d+\\s*[a-zA-Z]\\)\\s+\", t):\n",
        "        return True\n",
        "\n",
        "    # \"1a People\"\n",
        "    if re.match(r\"^\\d+[a-zA-Z]\\b\", t):\n",
        "        return True\n",
        "\n",
        "    # bullets\n",
        "    if re.match(r\"^[•\\-\\*]\\s+\", t):\n",
        "        return True\n",
        "\n",
        "    # Module/Unit/Lesson/Starter module — в любом регистре (MODULE 3 тоже)\n",
        "    if re.match(r\"^(module|unit|lesson|starter module|модуль|юнит|урок)\\b\", t, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    # капслок-заголовки (осторожно)\n",
        "    letters = re.sub(r\"[^A-Za-zА-Яа-яЁё]\", \"\", t)\n",
        "    if letters and sum(ch.isupper() for ch in letters) / max(len(letters), 1) > 0.8 and len(letters) >= 6:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def join_wrapped_lines_preserve_paragraphs(s: str) -> str:\n",
        "    \"\"\"\n",
        "    MVP (4): аккуратно склеиваем переносы строк внутри абзаца.\n",
        "    FIX: не склеиваем, если текущая строка сама является заголовком/маркером блока\n",
        "         (например, 'MODULE 3'), чтобы не превращать 'MODULE 3' + 'Body and Soul'\n",
        "         в одну строку.\n",
        "    \"\"\"\n",
        "    lines = s.split(\"\\n\")\n",
        "    out = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        if line.strip() == \"\":\n",
        "            out.append(\"\")\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        merged = line.rstrip()\n",
        "        j = i\n",
        "\n",
        "        while j + 1 < len(lines):\n",
        "            nxt = lines[j + 1]\n",
        "            if nxt.strip() == \"\":\n",
        "                break\n",
        "\n",
        "            # FIX 1: если текущая строка — маркер блока (Module/Starter/etc.), НЕ склеиваем дальше\n",
        "            if looks_like_new_block(merged):\n",
        "                break\n",
        "\n",
        "            # FIX 2: если следующая строка — новый блок/задание, тоже не склеиваем\n",
        "            if looks_like_new_block(nxt):\n",
        "                break\n",
        "\n",
        "            # сильная пунктуация в конце строки\n",
        "            if re.search(r\"[.!?…:;]$|[.!?…:;][\\\"”')\\]]*$\", merged.strip()):\n",
        "                break\n",
        "\n",
        "            merged = merged + \" \" + nxt.strip()\n",
        "            j += 1\n",
        "\n",
        "        out.append(merged)\n",
        "        i = j + 1\n",
        "\n",
        "    joined = \"\\n\".join(out)\n",
        "    joined = re.sub(r\"\\n{3,}\", \"\\n\\n\", joined)\n",
        "    return joined.strip()\n",
        "\n",
        "def extract_english_layer(s: str) -> str:\n",
        "    \"\"\"\n",
        "    MVP (5): EN-only слой:\n",
        "    - оставляем токены с латиницей\n",
        "    - оставляем цифры и базовую пунктуацию\n",
        "    - сохраняем \\n (чтобы можно было по страницам/блокам)\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r\"[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+|[.!?,;:\\-—()\\[\\]\\\"“”'…]+|\\n+\", s)\n",
        "    kept = []\n",
        "    for tok in tokens:\n",
        "        if tok.startswith(\"\\n\"):\n",
        "            kept.append(tok)\n",
        "            continue\n",
        "        if re.search(r\"[A-Za-z]\", tok):\n",
        "            kept.append(tok)\n",
        "        elif re.match(r\"^[0-9]+$\", tok):\n",
        "            kept.append(tok)\n",
        "        elif re.match(r\"^[.!?,;:\\-—()\\[\\]\\\"“”'…]+$\", tok):\n",
        "            kept.append(tok)\n",
        "\n",
        "    out = \" \".join(kept)\n",
        "    out = out.replace(\" \\n \", \"\\n\").replace(\" \\n\", \"\\n\").replace(\"\\n \", \"\\n\")\n",
        "    out = re.sub(r\"[ ]{2,}\", \" \", out)\n",
        "    out = re.sub(r\"\\s+([.!?,;:])\", r\"\\1\", out)  # убрать пробел перед пунктуацией\n",
        "    out = re.sub(r\"\\n{3,}\", \"\\n\\n\", out)\n",
        "    return out.strip()\n",
        "\n",
        "def detect_module_id(text_clean: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    UPDATED v2:\n",
        "    Ловит Module N / MODULE N / Модуль N (строго с начала строки),\n",
        "    даже если после номера на строке есть слова (например 'MODULE 3 Body and Soul').\n",
        "    'Starter module' игнорируем.\n",
        "    \"\"\"\n",
        "    for line in (text_clean or \"\").splitlines():\n",
        "        t = line.strip()\n",
        "        if re.match(r\"^starter\\s+module\\b\", t, re.IGNORECASE):\n",
        "            continue\n",
        "        m = re.match(r\"^(module|модуль)\\s+([0-9IVXLC]+)\\b\", t, re.IGNORECASE)\n",
        "        if m:\n",
        "            return m.group(2)\n",
        "    return None\n",
        "\n",
        "def split_into_pages(text: str, page_re: str = PAGE_RE_DEFAULT) -> List[Dict]:\n",
        "    text = normalize_whitespace(text)\n",
        "    page_re_comp = re.compile(page_re, re.MULTILINE)\n",
        "    matches = list(page_re_comp.finditer(text))\n",
        "\n",
        "    if not matches:\n",
        "        return [{\"page_num\": 1, \"text\": text}]\n",
        "\n",
        "    pages = []\n",
        "\n",
        "    # Если до первого маркера есть текст — считаем как PAGE 1\n",
        "    prefix = text[:matches[0].start()].strip()\n",
        "    if prefix:\n",
        "        pages.append({\"page_num\": 1, \"text\": prefix})\n",
        "\n",
        "    for idx, m in enumerate(matches):\n",
        "        page_num = int(m.group(1))\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(text)\n",
        "        page_text = text[start:end].strip()\n",
        "        pages.append({\"page_num\": page_num, \"text\": page_text})\n",
        "\n",
        "    return pages\n",
        "\n",
        "def preprocess_document(text_raw: str, page_re: str = PAGE_RE_DEFAULT) -> List[PageBlock]:\n",
        "    pages = split_into_pages(text_raw, page_re=page_re)\n",
        "\n",
        "    out_pages: List[PageBlock] = []\n",
        "    last_module: Optional[str] = None\n",
        "\n",
        "    for p in pages:\n",
        "        raw = p[\"text\"]\n",
        "        s = normalize_whitespace(raw)\n",
        "        s = dehyphenate_linebreaks(s)\n",
        "        s = join_wrapped_lines_preserve_paragraphs(s)\n",
        "\n",
        "        module_here = detect_module_id(s)\n",
        "        if module_here:\n",
        "            last_module = module_here\n",
        "\n",
        "        en = extract_english_layer(s)\n",
        "\n",
        "        out_pages.append(PageBlock(\n",
        "            page_num=p[\"page_num\"],\n",
        "            text_raw=raw,\n",
        "            text_clean=s,\n",
        "            text_en=en,\n",
        "            module_id=last_module\n",
        "        ))\n",
        "\n",
        "    return out_pages\n",
        "\n",
        "# --- RUN ---\n",
        "pages = preprocess_document(text_raw)\n",
        "\n",
        "print(\"Pages:\", len(pages), \"first:\", pages[0].page_num)\n",
        "print(pages[0].text_clean[:300])\n",
        "print(\"--- EN ---\")\n",
        "print(pages[0].text_en[:300])\n",
        "\n",
        "# Быстрый чек модулей (первые 10 отметок)\n",
        "mods = [(p.page_num, p.module_id) for p in pages if p.module_id is not None]\n",
        "print(\"First 10 module marks:\", mods[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lexicalrichness\n",
        "#токенизация\n",
        "!pip install spacy pandas\n",
        "!python -m spacy download en_core_web_sm #модель для англ яз\n",
        "!pip install python-Levenshtein\n",
        "!pip install transliterate\n",
        "!pip install deep-translator\n",
        "# textstat для автоматического анализа читаемости текста\n",
        "!pip install textstat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm1zMmR0Iq2e",
        "outputId": "84017700-b12e-4192-b752-45c924e34cae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lexicalrichness in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from lexicalrichness) (1.16.3)\n",
            "Requirement already satisfied: textblob>=0.15.3 in /usr/local/lib/python3.12/dist-packages (from lexicalrichness) (0.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from lexicalrichness) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lexicalrichness) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=1.0.0->lexicalrichness) (2.0.2)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob>=0.15.3->lexicalrichness) (3.9.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lexicalrichness) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->lexicalrichness) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->lexicalrichness) (2025.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob>=0.15.3->lexicalrichness) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob>=0.15.3->lexicalrichness) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob>=0.15.3->lexicalrichness) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob>=0.15.3->lexicalrichness) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lexicalrichness) (1.17.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.3)\n",
            "Requirement already satisfied: Levenshtein==0.27.3 in /usr/local/lib/python3.12/dist-packages (from python-Levenshtein) (0.27.3)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein==0.27.3->python-Levenshtein) (3.14.3)\n",
            "Requirement already satisfied: transliterate in /usr/local/lib/python3.12/dist-packages (1.10.2)\n",
            "Requirement already satisfied: six>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from transliterate) (1.17.0)\n",
            "Requirement already satisfied: deep-translator in /usr/local/lib/python3.12/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from deep-translator) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.11.12)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.12/dist-packages (0.7.12)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.12/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 2 — METRICS (by page / by module) [UPDATED v2]\n",
        "# =========================\n",
        "\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import textstat\n",
        "\n",
        "def tokenize_en(text: str) -> list[str]:\n",
        "    return re.findall(r\"[A-Za-z]+(?:'[A-Za-z]+)?\", (text or \"\").lower())\n",
        "\n",
        "def compute_ttr_family(tokens: list[str], segment_len: int = 100) -> dict:\n",
        "    n = len(tokens)\n",
        "    if n == 0:\n",
        "        return {\n",
        "            \"tokens\": 0, \"types\": 0,\n",
        "            \"ttr\": np.nan, \"rttr\": np.nan, \"cttr\": np.nan, f\"msttr_{segment_len}\": np.nan\n",
        "        }\n",
        "\n",
        "    types = len(set(tokens))\n",
        "    ttr  = types / n\n",
        "    rttr = types / math.sqrt(n)\n",
        "    cttr = types / math.sqrt(2 * n)\n",
        "\n",
        "    n_full = n // segment_len\n",
        "    if n_full > 0:\n",
        "        seg_ttrs = []\n",
        "        for i in range(n_full):\n",
        "            seg = tokens[i*segment_len:(i+1)*segment_len]\n",
        "            seg_ttrs.append(len(set(seg)) / segment_len)\n",
        "        msttr = float(np.mean(seg_ttrs))\n",
        "    else:\n",
        "        msttr = np.nan\n",
        "\n",
        "    return {\n",
        "        \"tokens\": n,\n",
        "        \"types\": types,\n",
        "        \"ttr\": ttr,\n",
        "        \"rttr\": rttr,\n",
        "        \"cttr\": cttr,\n",
        "        f\"msttr_{segment_len}\": msttr\n",
        "    }\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return a / b if b else np.nan\n",
        "\n",
        "def compute_textstat_metrics(text: str) -> dict:\n",
        "    text = text or \"\"\n",
        "    words = textstat.lexicon_count(text)\n",
        "    sents = textstat.sentence_count(text)\n",
        "    syll  = textstat.syllable_count(text)\n",
        "\n",
        "    return {\n",
        "        \"flesch_reading_ease\": textstat.flesch_reading_ease(text) if words else np.nan,\n",
        "        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(text) if words else np.nan,\n",
        "        \"words_total\": words,\n",
        "        \"sentences_total\": sents,\n",
        "        \"syllables_total\": syll,\n",
        "        \"avg_words_per_sentence\": safe_div(words, sents),\n",
        "    }\n",
        "\n",
        "def compute_metrics_for_text(text: str, segment_len: int = 100) -> dict:\n",
        "    m = {}\n",
        "    m.update(compute_textstat_metrics(text))\n",
        "    tokens = tokenize_en(text)\n",
        "    m.update(compute_ttr_family(tokens, segment_len=segment_len))\n",
        "    return m\n",
        "\n",
        "# --- METRICS BY PAGE (EN-layer) ---\n",
        "rows = []\n",
        "for p in pages:\n",
        "    m = compute_metrics_for_text(p.text_en, segment_len=100)\n",
        "    rows.append({\n",
        "        \"page_num\": p.page_num,\n",
        "        \"module_id\": p.module_id,\n",
        "        **m\n",
        "    })\n",
        "\n",
        "by_page = pd.DataFrame(rows).sort_values(\"page_num\")\n",
        "\n",
        "# --- flags for \"too little text\" (useful for UI/explanations) ---\n",
        "MIN_TOKENS = 50\n",
        "MIN_WORDS  = 50\n",
        "\n",
        "by_page[\"is_sparse\"] = (by_page[\"tokens\"] < MIN_TOKENS) | (by_page[\"words_total\"] < MIN_WORDS)\n",
        "\n",
        "def sparse_reason(row):\n",
        "    reasons = []\n",
        "    if row[\"tokens\"] < MIN_TOKENS:\n",
        "        reasons.append(f\"tokens<{MIN_TOKENS}\")\n",
        "    if row[\"words_total\"] < MIN_WORDS:\n",
        "        reasons.append(f\"words<{MIN_WORDS}\")\n",
        "    return \", \".join(reasons) if reasons else \"\"\n",
        "\n",
        "by_page[\"sparse_reason\"] = by_page.apply(sparse_reason, axis=1)\n",
        "\n",
        "display(by_page.head(10))\n",
        "\n",
        "# --- SAVE ---\n",
        "by_page.to_excel(\"metrics_by_page.xlsx\", index=False)\n",
        "\n",
        "# --- METRICS BY MODULE (means) ---\n",
        "# v2 FIX: не усредняем page_num и служебные поля\n",
        "metric_cols = [c for c in by_page.columns if c not in (\"page_num\", \"is_sparse\", \"sparse_reason\")]\n",
        "\n",
        "by_module = (\n",
        "    by_page[~by_page[\"is_sparse\"]]\n",
        "    .groupby(\"module_id\", dropna=False)[metric_cols]\n",
        "    .mean(numeric_only=True)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# если не хочешь строку с module_id = NaN (страницы до первого модуля), раскомментируй:\n",
        "# by_module = by_module[by_module[\"module_id\"].notna()].copy()\n",
        "\n",
        "display(by_module)\n",
        "by_module.to_excel(\"metrics_by_module.xlsx\", index=False)\n",
        "\n",
        "print(\"OK -> metrics_by_page.xlsx, metrics_by_module.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "obKRQdrvEQ_1",
        "outputId": "964c5ac5-ea8b-4862-d1c0-771f10de8ac6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   page_num module_id  flesch_reading_ease  flesch_kincaid_grade  words_total  \\\n",
              "0         1      None             5.265000             16.996667           18   \n",
              "1         2      None            54.725000              6.620000            4   \n",
              "2         3      None            63.885209              7.761238          261   \n",
              "3         4      None            48.617462              9.927493          361   \n",
              "4         5      None            19.756000             20.263429          550   \n",
              "5         6      None            75.980359              5.250473          396   \n",
              "6         7      None            90.253021              2.645361          612   \n",
              "7         8         1            59.879886              8.203095          199   \n",
              "8         9         1            63.755330              9.069124          530   \n",
              "9        10         1            72.655176              6.399669          659   \n",
              "\n",
              "   sentences_total  syllables_total  avg_words_per_sentence  tokens  types  \\\n",
              "0                1               39               18.000000      17     17   \n",
              "1                1                7                4.000000       2      2   \n",
              "2               19              398               13.736842     173    126   \n",
              "3               26              615               13.884615     295    158   \n",
              "4               14              957               39.285714     528    260   \n",
              "5               38              563               10.421053     349    217   \n",
              "6               77              785                7.948052     551    272   \n",
              "7               15              314               13.266667     187    125   \n",
              "8               28              776               18.928571     518    273   \n",
              "9               50              941               13.180000     619    329   \n",
              "\n",
              "        ttr       rttr      cttr  msttr_100  is_sparse        sparse_reason  \n",
              "0  1.000000   4.123106  2.915476        NaN       True  tokens<50, words<50  \n",
              "1  1.000000   1.414214  1.000000        NaN       True  tokens<50, words<50  \n",
              "2  0.728324   9.579603  6.773802   0.790000      False                       \n",
              "3  0.535593   9.199116  6.504757   0.710000      False                       \n",
              "4  0.492424  11.315048  8.000947   0.714000      False                       \n",
              "5  0.621777  11.615744  8.213571   0.720000      False                       \n",
              "6  0.493648  11.587590  8.193663   0.682000      False                       \n",
              "7  0.668449   9.140905  6.463596   0.780000      False                       \n",
              "8  0.527027  11.994931  8.481697   0.742000      False                       \n",
              "9  0.531502  13.223626  9.350516   0.738333      False                       "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2103b46-d91b-4b0f-8f19-a56b481cc415\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_num</th>\n",
              "      <th>module_id</th>\n",
              "      <th>flesch_reading_ease</th>\n",
              "      <th>flesch_kincaid_grade</th>\n",
              "      <th>words_total</th>\n",
              "      <th>sentences_total</th>\n",
              "      <th>syllables_total</th>\n",
              "      <th>avg_words_per_sentence</th>\n",
              "      <th>tokens</th>\n",
              "      <th>types</th>\n",
              "      <th>ttr</th>\n",
              "      <th>rttr</th>\n",
              "      <th>cttr</th>\n",
              "      <th>msttr_100</th>\n",
              "      <th>is_sparse</th>\n",
              "      <th>sparse_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>5.265000</td>\n",
              "      <td>16.996667</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.123106</td>\n",
              "      <td>2.915476</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>tokens&lt;50, words&lt;50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>54.725000</td>\n",
              "      <td>6.620000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.414214</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>tokens&lt;50, words&lt;50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>63.885209</td>\n",
              "      <td>7.761238</td>\n",
              "      <td>261</td>\n",
              "      <td>19</td>\n",
              "      <td>398</td>\n",
              "      <td>13.736842</td>\n",
              "      <td>173</td>\n",
              "      <td>126</td>\n",
              "      <td>0.728324</td>\n",
              "      <td>9.579603</td>\n",
              "      <td>6.773802</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>48.617462</td>\n",
              "      <td>9.927493</td>\n",
              "      <td>361</td>\n",
              "      <td>26</td>\n",
              "      <td>615</td>\n",
              "      <td>13.884615</td>\n",
              "      <td>295</td>\n",
              "      <td>158</td>\n",
              "      <td>0.535593</td>\n",
              "      <td>9.199116</td>\n",
              "      <td>6.504757</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>19.756000</td>\n",
              "      <td>20.263429</td>\n",
              "      <td>550</td>\n",
              "      <td>14</td>\n",
              "      <td>957</td>\n",
              "      <td>39.285714</td>\n",
              "      <td>528</td>\n",
              "      <td>260</td>\n",
              "      <td>0.492424</td>\n",
              "      <td>11.315048</td>\n",
              "      <td>8.000947</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>75.980359</td>\n",
              "      <td>5.250473</td>\n",
              "      <td>396</td>\n",
              "      <td>38</td>\n",
              "      <td>563</td>\n",
              "      <td>10.421053</td>\n",
              "      <td>349</td>\n",
              "      <td>217</td>\n",
              "      <td>0.621777</td>\n",
              "      <td>11.615744</td>\n",
              "      <td>8.213571</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>90.253021</td>\n",
              "      <td>2.645361</td>\n",
              "      <td>612</td>\n",
              "      <td>77</td>\n",
              "      <td>785</td>\n",
              "      <td>7.948052</td>\n",
              "      <td>551</td>\n",
              "      <td>272</td>\n",
              "      <td>0.493648</td>\n",
              "      <td>11.587590</td>\n",
              "      <td>8.193663</td>\n",
              "      <td>0.682000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>59.879886</td>\n",
              "      <td>8.203095</td>\n",
              "      <td>199</td>\n",
              "      <td>15</td>\n",
              "      <td>314</td>\n",
              "      <td>13.266667</td>\n",
              "      <td>187</td>\n",
              "      <td>125</td>\n",
              "      <td>0.668449</td>\n",
              "      <td>9.140905</td>\n",
              "      <td>6.463596</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>63.755330</td>\n",
              "      <td>9.069124</td>\n",
              "      <td>530</td>\n",
              "      <td>28</td>\n",
              "      <td>776</td>\n",
              "      <td>18.928571</td>\n",
              "      <td>518</td>\n",
              "      <td>273</td>\n",
              "      <td>0.527027</td>\n",
              "      <td>11.994931</td>\n",
              "      <td>8.481697</td>\n",
              "      <td>0.742000</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>72.655176</td>\n",
              "      <td>6.399669</td>\n",
              "      <td>659</td>\n",
              "      <td>50</td>\n",
              "      <td>941</td>\n",
              "      <td>13.180000</td>\n",
              "      <td>619</td>\n",
              "      <td>329</td>\n",
              "      <td>0.531502</td>\n",
              "      <td>13.223626</td>\n",
              "      <td>9.350516</td>\n",
              "      <td>0.738333</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2103b46-d91b-4b0f-8f19-a56b481cc415')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2103b46-d91b-4b0f-8f19-a56b481cc415 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2103b46-d91b-4b0f-8f19-a56b481cc415');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c94ae94-829b-4fa3-8966-08aeaed4023c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c94ae94-829b-4fa3-8966-08aeaed4023c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c94ae94-829b-4fa3-8966-08aeaed4023c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"OK -> metrics_by_page\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"page_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"module_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flesch_reading_ease\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.66518781260081,\n        \"min\": 5.265000000000015,\n        \"max\": 90.25302139037434,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          63.75533018867927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flesch_kincaid_grade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.372034832904565,\n        \"min\": 2.6453611747729404,\n        \"max\": 20.263428571428573,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9.069123989218326\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 235,\n        \"min\": 4,\n        \"max\": 659,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          530\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 1,\n        \"max\": 77,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"syllables_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 343,\n        \"min\": 7,\n        \"max\": 957,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_words_per_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.512446609168286,\n        \"min\": 4.0,\n        \"max\": 39.285714285714285,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          18.928571428571427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 225,\n        \"min\": 2,\n        \"max\": 619,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          518\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"types\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111,\n        \"min\": 2,\n        \"max\": 329,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          273\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1951710166844862,\n        \"min\": 0.49242424242424243,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.527027027027027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7477314943935807,\n        \"min\": 1.414213562373095,\n        \"max\": 13.223626478906416,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          11.994931361970288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6500463537520944,\n        \"min\": 1.0,\n        \"max\": 9.350515955112714,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8.48169730591638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"msttr_100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03626968540482643,\n        \"min\": 0.682,\n        \"max\": 0.79,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sparse\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sparse_reason\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  module_id  flesch_reading_ease  flesch_kincaid_grade  words_total  \\\n",
              "0         1            60.422752             11.009324   609.923077   \n",
              "1         2            64.672460              9.054777   586.458333   \n",
              "2         3            56.425265             12.449376   570.440000   \n",
              "3         4            56.199862             12.275317   588.083333   \n",
              "4         5            68.126721              7.261541   625.500000   \n",
              "5         6            57.902127             11.807032   536.317647   \n",
              "6       NaN            59.698410              9.169599   436.000000   \n",
              "\n",
              "   sentences_total  syllables_total  avg_words_per_sentence      tokens  \\\n",
              "0        42.307692       871.423077               24.867408  589.461538   \n",
              "1        43.791667       843.166667               19.385744  564.250000   \n",
              "2        39.480000       814.440000               28.419675  549.720000   \n",
              "3        38.791667       846.208333               27.592482  566.250000   \n",
              "4        47.125000       913.291667               14.106803  604.708333   \n",
              "5        39.047059       770.941176               26.663227  506.764706   \n",
              "6        34.800000       663.600000               17.055255  379.200000   \n",
              "\n",
              "        types       ttr       rttr      cttr  msttr_100  \n",
              "0  274.884615  0.483768  11.367290  8.037888   0.705549  \n",
              "1  280.916667  0.515609  11.881588  8.401552   0.726078  \n",
              "2  269.240000  0.503370  11.454646  8.099658   0.714359  \n",
              "3  284.291667  0.512870  11.942031  8.444291   0.723658  \n",
              "4  279.041667  0.476916  11.397654  8.059359   0.698320  \n",
              "5  263.364706  0.539899  11.780925  8.330372   0.723945  \n",
              "6  206.600000  0.574353  10.659420  7.537348   0.723200  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4129fbc7-c552-46fa-ae22-b3c6ba5c2e4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>module_id</th>\n",
              "      <th>flesch_reading_ease</th>\n",
              "      <th>flesch_kincaid_grade</th>\n",
              "      <th>words_total</th>\n",
              "      <th>sentences_total</th>\n",
              "      <th>syllables_total</th>\n",
              "      <th>avg_words_per_sentence</th>\n",
              "      <th>tokens</th>\n",
              "      <th>types</th>\n",
              "      <th>ttr</th>\n",
              "      <th>rttr</th>\n",
              "      <th>cttr</th>\n",
              "      <th>msttr_100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60.422752</td>\n",
              "      <td>11.009324</td>\n",
              "      <td>609.923077</td>\n",
              "      <td>42.307692</td>\n",
              "      <td>871.423077</td>\n",
              "      <td>24.867408</td>\n",
              "      <td>589.461538</td>\n",
              "      <td>274.884615</td>\n",
              "      <td>0.483768</td>\n",
              "      <td>11.367290</td>\n",
              "      <td>8.037888</td>\n",
              "      <td>0.705549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>64.672460</td>\n",
              "      <td>9.054777</td>\n",
              "      <td>586.458333</td>\n",
              "      <td>43.791667</td>\n",
              "      <td>843.166667</td>\n",
              "      <td>19.385744</td>\n",
              "      <td>564.250000</td>\n",
              "      <td>280.916667</td>\n",
              "      <td>0.515609</td>\n",
              "      <td>11.881588</td>\n",
              "      <td>8.401552</td>\n",
              "      <td>0.726078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>56.425265</td>\n",
              "      <td>12.449376</td>\n",
              "      <td>570.440000</td>\n",
              "      <td>39.480000</td>\n",
              "      <td>814.440000</td>\n",
              "      <td>28.419675</td>\n",
              "      <td>549.720000</td>\n",
              "      <td>269.240000</td>\n",
              "      <td>0.503370</td>\n",
              "      <td>11.454646</td>\n",
              "      <td>8.099658</td>\n",
              "      <td>0.714359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>56.199862</td>\n",
              "      <td>12.275317</td>\n",
              "      <td>588.083333</td>\n",
              "      <td>38.791667</td>\n",
              "      <td>846.208333</td>\n",
              "      <td>27.592482</td>\n",
              "      <td>566.250000</td>\n",
              "      <td>284.291667</td>\n",
              "      <td>0.512870</td>\n",
              "      <td>11.942031</td>\n",
              "      <td>8.444291</td>\n",
              "      <td>0.723658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>68.126721</td>\n",
              "      <td>7.261541</td>\n",
              "      <td>625.500000</td>\n",
              "      <td>47.125000</td>\n",
              "      <td>913.291667</td>\n",
              "      <td>14.106803</td>\n",
              "      <td>604.708333</td>\n",
              "      <td>279.041667</td>\n",
              "      <td>0.476916</td>\n",
              "      <td>11.397654</td>\n",
              "      <td>8.059359</td>\n",
              "      <td>0.698320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>57.902127</td>\n",
              "      <td>11.807032</td>\n",
              "      <td>536.317647</td>\n",
              "      <td>39.047059</td>\n",
              "      <td>770.941176</td>\n",
              "      <td>26.663227</td>\n",
              "      <td>506.764706</td>\n",
              "      <td>263.364706</td>\n",
              "      <td>0.539899</td>\n",
              "      <td>11.780925</td>\n",
              "      <td>8.330372</td>\n",
              "      <td>0.723945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>59.698410</td>\n",
              "      <td>9.169599</td>\n",
              "      <td>436.000000</td>\n",
              "      <td>34.800000</td>\n",
              "      <td>663.600000</td>\n",
              "      <td>17.055255</td>\n",
              "      <td>379.200000</td>\n",
              "      <td>206.600000</td>\n",
              "      <td>0.574353</td>\n",
              "      <td>10.659420</td>\n",
              "      <td>7.537348</td>\n",
              "      <td>0.723200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4129fbc7-c552-46fa-ae22-b3c6ba5c2e4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4129fbc7-c552-46fa-ae22-b3c6ba5c2e4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4129fbc7-c552-46fa-ae22-b3c6ba5c2e4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-442b8fcb-3ba9-45f4-b076-18d8bc699c77\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-442b8fcb-3ba9-45f4-b076-18d8bc699c77')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-442b8fcb-3ba9-45f4-b076-18d8bc699c77 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "by_module",
              "summary": "{\n  \"name\": \"by_module\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"module_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"1\",\n          \"2\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flesch_reading_ease\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.435989497899446,\n        \"min\": 56.19986190843502,\n        \"max\": 68.1267212557796,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          60.42275236807364,\n          64.67245976328637,\n          57.902127219891554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"flesch_kincaid_grade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9678180618664625,\n        \"min\": 7.2615410999730186,\n        \"max\": 12.449375684782437,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          11.009324339381006,\n          9.054777357659782,\n          11.807032385622872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.46148843412833,\n        \"min\": 436.0,\n        \"max\": 625.5,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          609.9230769230769,\n          586.4583333333334,\n          536.3176470588236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentences_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.001416555728041,\n        \"min\": 34.8,\n        \"max\": 47.125,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          42.30769230769231,\n          43.791666666666664,\n          39.04705882352941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"syllables_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81.06472608599383,\n        \"min\": 663.6,\n        \"max\": 913.2916666666666,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          871.4230769230769,\n          843.1666666666666,\n          770.9411764705883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_words_per_sentence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.6811495303278905,\n        \"min\": 14.106803438926406,\n        \"max\": 28.41967486931566,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          24.867408148399,\n          19.385744381443423,\n          26.663226960004515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76.27942678632068,\n        \"min\": 379.2,\n        \"max\": 604.7083333333334,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          589.4615384615385,\n          564.25,\n          506.7647058823529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"types\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.925828622294027,\n        \"min\": 206.6,\n        \"max\": 284.2916666666667,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          274.88461538461536,\n          280.9166666666667,\n          263.36470588235295\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.033437334163607994,\n        \"min\": 0.476915709803315,\n        \"max\": 0.5743531158737695,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4837680110260516,\n          0.5156085074228279,\n          0.5398993627201654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43905193401342807,\n        \"min\": 10.65941983372625,\n        \"max\": 11.94203074236034,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          11.367290013091916,\n          11.881588305901616,\n          11.780924995500259\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cttr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31045659983396406,\n        \"min\": 7.537348047942212,\n        \"max\": 8.444290919061217,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          8.037887851971412,\n          8.401551662369815,\n          8.330371952968331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"msttr_100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01078811799766663,\n        \"min\": 0.6983201058201058,\n        \"max\": 0.7260783730158731,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7055488400488401,\n          0.7260783730158731,\n          0.7239450046685341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK -> metrics_by_page.xlsx, metrics_by_module.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 3 — CEFR (overall + by page + by module) [for pages]\n",
        "# =========================\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import spacy\n",
        "\n",
        "# --- (1) spaCy model ---\n",
        "# Если модель не установлена в Colab, раскомментируй:\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])  # NER не нужен\n",
        "# ускоряем (опционально)\n",
        "try:\n",
        "    nlp.max_length = 5_000_000\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# --- (2) Load CEFR lexicon ---\n",
        "CEFR_PATH = \"/content/len_cefr.csv\"   # <-- путь к твоей базе CEFR\n",
        "\n",
        "cefr_order = {\"A1\": 1, \"A2\": 2, \"B1\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
        "cefr_levels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
        "\n",
        "# если хочешь сохранять старый \"костыль\", включи:\n",
        "LEVEL_MAP = {\"C1\": \"B1\"}   # <-- можно поставить {} если не нужно\n",
        "\n",
        "\n",
        "def load_cefr_lexicon(path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Читает таблицу со столбцами:\n",
        "      Word, CEFR Level\n",
        "    Поддерживает csv с ',' или ';'.\n",
        "    Возвращает dict: lemma(word)-> минимальный уровень\n",
        "    \"\"\"\n",
        "    # пробуем разные разделители\n",
        "    df = None\n",
        "    for sep in [\",\", \";\"]:\n",
        "        try:\n",
        "            df_try = pd.read_csv(path, sep=sep, encoding=\"utf-8\")\n",
        "            if {\"Word\", \"CEFR Level\"}.issubset(df_try.columns):\n",
        "                df = df_try\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if df is None:\n",
        "        raise ValueError(\"Не смог прочитать CEFR csv. Нужны колонки: 'Word', 'CEFR Level'.\")\n",
        "\n",
        "    word_levels = {}\n",
        "    for _, row in df.iterrows():\n",
        "        w = str(row[\"Word\"]).strip().lower()\n",
        "        lvl = str(row[\"CEFR Level\"]).strip().upper()\n",
        "\n",
        "        if not w or lvl not in cefr_order:\n",
        "            continue\n",
        "\n",
        "        if lvl in LEVEL_MAP:\n",
        "            lvl = LEVEL_MAP[lvl]\n",
        "\n",
        "        if w in word_levels:\n",
        "            # берём минимальный (самый простой) уровень как приоритет\n",
        "            if cefr_order[lvl] < cefr_order.get(word_levels[w], 999):\n",
        "                word_levels[w] = lvl\n",
        "        else:\n",
        "            word_levels[w] = lvl\n",
        "\n",
        "    return word_levels\n",
        "\n",
        "\n",
        "word_levels = load_cefr_lexicon(CEFR_PATH)\n",
        "print(\"Loaded CEFR entries:\", len(word_levels))\n",
        "\n",
        "\n",
        "# --- (3) Token/lemma extraction ---\n",
        "LEMMA_RE = re.compile(r\"^[a-z]+$\")  # только латиница (леммы)\n",
        "\n",
        "EXCLUDE_STOPWORDS = True  # как в твоём старом коде\n",
        "\n",
        "def iter_lemmas_with_pos(doc):\n",
        "    \"\"\"\n",
        "    Возвращает (lemma, pos) по токенам.\n",
        "    Берём только слова (alpha), только латиницу, без пунктуации.\n",
        "    \"\"\"\n",
        "    for token in doc:\n",
        "        if token.is_punct or token.is_space:\n",
        "            continue\n",
        "        if EXCLUDE_STOPWORDS and token.is_stop:\n",
        "            continue\n",
        "        if not token.is_alpha:\n",
        "            continue\n",
        "\n",
        "        lemma = (token.lemma_ or token.text).lower().strip()\n",
        "        if not lemma or not LEMMA_RE.match(lemma):\n",
        "            continue\n",
        "\n",
        "        yield lemma, token.pos_\n",
        "\n",
        "\n",
        "# --- (4) CEFR for ALL pages (fast via nlp.pipe) ---\n",
        "# Берём EN-layer из предобработки\n",
        "page_texts = [p.text_en for p in pages]\n",
        "page_meta  = [(p.page_num, p.module_id) for p in pages]\n",
        "\n",
        "# Частоты по страницам\n",
        "page_level_token_counts = []\n",
        "page_level_type_counts  = []\n",
        "page_total_tokens = []\n",
        "page_known_tokens = []\n",
        "\n",
        "# Общие частоты лемм по всему документу (для word table)\n",
        "global_lemma_freq = Counter()\n",
        "global_pos_for_lemma = {}  # lemma -> POS (первое встреченное)\n",
        "\n",
        "docs = nlp.pipe(page_texts, batch_size=16)\n",
        "\n",
        "for (page_num, module_id), doc in zip(page_meta, docs):\n",
        "    lemmas = []\n",
        "    for lemma, pos in iter_lemmas_with_pos(doc):\n",
        "        lemmas.append(lemma)\n",
        "        global_lemma_freq[lemma] += 1\n",
        "        global_pos_for_lemma.setdefault(lemma, pos)\n",
        "\n",
        "    page_total_tokens.append(len(lemmas))\n",
        "\n",
        "    # уровень для каждого токена\n",
        "    levels_for_tokens = []\n",
        "    for lm in lemmas:\n",
        "        lvl = word_levels.get(lm)\n",
        "        if lvl:\n",
        "            levels_for_tokens.append(lvl)\n",
        "\n",
        "    page_known_tokens.append(len(levels_for_tokens))\n",
        "\n",
        "    # tokens per level\n",
        "    token_counts = Counter(levels_for_tokens)\n",
        "\n",
        "    # types per level\n",
        "    uniq = set(lemmas)\n",
        "    type_levels = []\n",
        "    for lm in uniq:\n",
        "        lvl = word_levels.get(lm)\n",
        "        if lvl:\n",
        "            type_levels.append(lvl)\n",
        "    type_counts = Counter(type_levels)\n",
        "\n",
        "    page_level_token_counts.append(token_counts)\n",
        "    page_level_type_counts.append(type_counts)\n",
        "\n",
        "\n",
        "# --- (5) Build \"word-level table\" for whole document ---\n",
        "rows = []\n",
        "for lemma, freq in global_lemma_freq.items():\n",
        "    lvl = word_levels.get(lemma)\n",
        "    if not lvl:\n",
        "        continue\n",
        "    rows.append({\n",
        "        \"word\": lemma,\n",
        "        \"level\": lvl,\n",
        "        \"frequency\": freq,\n",
        "        \"pos\": global_pos_for_lemma.get(lemma, \"X\")\n",
        "    })\n",
        "\n",
        "df_words = pd.DataFrame(rows)\n",
        "df_words = df_words.sort_values(by=[\"level\", \"frequency\"], ascending=[True, False]).reset_index(drop=True)\n",
        "\n",
        "# Топ-10 по частоте на уровень\n",
        "df_top10 = (\n",
        "    df_words.groupby(\"level\", dropna=False)\n",
        "    .apply(lambda x: x.nlargest(10, \"frequency\"))\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# POS distribution (только по словам с известным CEFR)\n",
        "df_pos = df_words[\"pos\"].value_counts().reset_index()\n",
        "df_pos.columns = [\"pos\", \"count\"]\n",
        "\n",
        "\n",
        "# --- (6) Build by_page CEFR distribution table ---\n",
        "def expand_counts(counter: Counter, prefix: str) -> dict:\n",
        "    out = {}\n",
        "    for lvl in cefr_levels:\n",
        "        out[f\"{prefix}_{lvl}\"] = int(counter.get(lvl, 0))\n",
        "    return out\n",
        "\n",
        "by_page_rows = []\n",
        "for (page_num, module_id), tok_cnt, typ_cnt, total_toks, known_toks in zip(\n",
        "    page_meta, page_level_token_counts, page_level_type_counts, page_total_tokens, page_known_tokens\n",
        "):\n",
        "    row = {\n",
        "        \"page_num\": page_num,\n",
        "        \"module_id\": module_id,\n",
        "        \"total_tokens\": int(total_toks),\n",
        "        \"known_tokens\": int(known_toks),\n",
        "        \"known_share\": (known_toks / total_toks) if total_toks else np.nan,\n",
        "    }\n",
        "    row.update(expand_counts(tok_cnt, \"tokens\"))\n",
        "    row.update(expand_counts(typ_cnt, \"types\"))\n",
        "\n",
        "    # проценты по токенам (среди known_tokens)\n",
        "    for lvl in cefr_levels:\n",
        "        denom = known_toks if known_toks else 0\n",
        "        row[f\"tokens_pct_{lvl}\"] = (row[f\"tokens_{lvl}\"] / denom) if denom else np.nan\n",
        "\n",
        "    # проценты по типам (среди types known)\n",
        "    types_known = sum(row[f\"types_{lvl}\"] for lvl in cefr_levels)\n",
        "    for lvl in cefr_levels:\n",
        "        row[f\"types_pct_{lvl}\"] = (row[f\"types_{lvl}\"] / types_known) if types_known else np.nan\n",
        "\n",
        "    by_page_rows.append(row)\n",
        "\n",
        "df_cefr_by_page = pd.DataFrame(by_page_rows).sort_values(\"page_num\").reset_index(drop=True)\n",
        "\n",
        "# флаг \"мало текста\" (чтобы на сайте объяснять, что метрики нестабильны)\n",
        "MIN_TOKENS_CEFR = 50\n",
        "df_cefr_by_page[\"is_sparse_cefr\"] = df_cefr_by_page[\"total_tokens\"] < MIN_TOKENS_CEFR\n",
        "\n",
        "\n",
        "# --- (7) Aggregate by module ---\n",
        "# (если module_id None — будет отдельная группа None)\n",
        "agg_cols = [c for c in df_cefr_by_page.columns if c not in (\"page_num\")]\n",
        "df_cefr_by_module = (\n",
        "    df_cefr_by_page.groupby(\"module_id\", dropna=False)[agg_cols]\n",
        "    .sum(numeric_only=True)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# доли/проценты по модулю пересчитаем аккуратно:\n",
        "def recompute_shares(df_mod: pd.DataFrame) -> pd.DataFrame:\n",
        "    df_mod = df_mod.copy()\n",
        "    # known_share\n",
        "    df_mod[\"known_share\"] = df_mod[\"known_tokens\"] / df_mod[\"total_tokens\"].replace(0, np.nan)\n",
        "\n",
        "    for lvl in cefr_levels:\n",
        "        df_mod[f\"tokens_pct_{lvl}\"] = df_mod[f\"tokens_{lvl}\"] / df_mod[\"known_tokens\"].replace(0, np.nan)\n",
        "\n",
        "    # types_pct по модулю: сначала посчитать types_known\n",
        "    types_known = sum(df_mod[f\"types_{lvl}\"] for lvl in cefr_levels)\n",
        "    for lvl in cefr_levels:\n",
        "        df_mod[f\"types_pct_{lvl}\"] = df_mod[f\"types_{lvl}\"] / types_known.replace(0, np.nan)\n",
        "\n",
        "    return df_mod\n",
        "\n",
        "df_cefr_by_module = recompute_shares(df_cefr_by_module)\n",
        "\n",
        "\n",
        "# --- (8) Save outputs ---\n",
        "df_words.to_csv(\"cefr_word_levels_table.csv\", index=False, encoding=\"utf-8\")\n",
        "df_top10.to_csv(\"cefr_top10_by_level.csv\", index=False, encoding=\"utf-8\")\n",
        "df_pos.to_csv(\"cefr_pos_distribution.csv\", index=False, encoding=\"utf-8\")\n",
        "df_cefr_by_page.to_csv(\"cefr_by_page.csv\", index=False, encoding=\"utf-8\")\n",
        "df_cefr_by_module.to_csv(\"cefr_by_module.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "with pd.ExcelWriter(\"cefr_outputs.xlsx\") as w:\n",
        "    df_words.to_excel(w, sheet_name=\"word_table\", index=False)\n",
        "    df_top10.to_excel(w, sheet_name=\"top10_by_level\", index=False)\n",
        "    df_pos.to_excel(w, sheet_name=\"pos_distribution\", index=False)\n",
        "    df_cefr_by_page.to_excel(w, sheet_name=\"by_page\", index=False)\n",
        "    df_cefr_by_module.to_excel(w, sheet_name=\"by_module\", index=False)\n",
        "\n",
        "print(\"OK -> cefr_outputs.xlsx + csv files\")\n",
        "\n",
        "display(df_cefr_by_page.head(10))\n",
        "display(df_cefr_by_module.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "s24nwvrkSYT7",
        "outputId": "6646b0a5-0f1d-4c29-9346-1e7b92ce790b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CEFR entries: 7654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-229003683.py:174: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.nlargest(10, \"frequency\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK -> cefr_outputs.xlsx + csv files\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   page_num module_id  total_tokens  known_tokens  known_share  tokens_A1  \\\n",
              "0         1      None            17             5     0.294118          1   \n",
              "1         2      None             2             2     1.000000          0   \n",
              "2         3      None           111            64     0.576577         11   \n",
              "3         4      None           236           165     0.699153         71   \n",
              "4         5      None           381           302     0.792651        113   \n",
              "5         6      None           236           173     0.733051         68   \n",
              "6         7      None           265           202     0.762264         99   \n",
              "7         8         1           109            91     0.834862         44   \n",
              "8         9         1           281           226     0.804270        113   \n",
              "9        10         1           308           247     0.801948        108   \n",
              "\n",
              "   tokens_A2  tokens_B1  tokens_B2  tokens_C1  ...  tokens_pct_B2  \\\n",
              "0          1          2          1          0  ...       0.200000   \n",
              "1          1          0          1          0  ...       0.500000   \n",
              "2         15         21         17          0  ...       0.265625   \n",
              "3         32         39         23          0  ...       0.139394   \n",
              "4         81         44         64          0  ...       0.211921   \n",
              "5         40         34         31          0  ...       0.179191   \n",
              "6         40         30         33          0  ...       0.163366   \n",
              "7         23         14         10          0  ...       0.109890   \n",
              "8         55         29         29          0  ...       0.128319   \n",
              "9         61         46         32          0  ...       0.129555   \n",
              "\n",
              "   tokens_pct_C1  tokens_pct_C2  types_pct_A1  types_pct_A2  types_pct_B1  \\\n",
              "0            0.0            0.0      0.200000      0.200000      0.400000   \n",
              "1            0.0            0.0      0.000000      0.500000      0.000000   \n",
              "2            0.0            0.0      0.160000      0.220000      0.360000   \n",
              "3            0.0            0.0      0.336364      0.227273      0.281818   \n",
              "4            0.0            0.0      0.419540      0.235632      0.189655   \n",
              "5            0.0            0.0      0.352113      0.239437      0.197183   \n",
              "6            0.0            0.0      0.491124      0.177515      0.171598   \n",
              "7            0.0            0.0      0.464789      0.239437      0.183099   \n",
              "8            0.0            0.0      0.435897      0.282051      0.153846   \n",
              "9            0.0            0.0      0.414365      0.254144      0.198895   \n",
              "\n",
              "   types_pct_B2  types_pct_C1  types_pct_C2  is_sparse_cefr  \n",
              "0      0.200000           0.0           0.0            True  \n",
              "1      0.500000           0.0           0.0            True  \n",
              "2      0.260000           0.0           0.0           False  \n",
              "3      0.154545           0.0           0.0           False  \n",
              "4      0.155172           0.0           0.0           False  \n",
              "5      0.211268           0.0           0.0           False  \n",
              "6      0.159763           0.0           0.0           False  \n",
              "7      0.112676           0.0           0.0           False  \n",
              "8      0.128205           0.0           0.0           False  \n",
              "9      0.132597           0.0           0.0           False  \n",
              "\n",
              "[10 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-569196ea-bf24-4ad9-826c-33f2155fff32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_num</th>\n",
              "      <th>module_id</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>known_tokens</th>\n",
              "      <th>known_share</th>\n",
              "      <th>tokens_A1</th>\n",
              "      <th>tokens_A2</th>\n",
              "      <th>tokens_B1</th>\n",
              "      <th>tokens_B2</th>\n",
              "      <th>tokens_C1</th>\n",
              "      <th>...</th>\n",
              "      <th>tokens_pct_B2</th>\n",
              "      <th>tokens_pct_C1</th>\n",
              "      <th>tokens_pct_C2</th>\n",
              "      <th>types_pct_A1</th>\n",
              "      <th>types_pct_A2</th>\n",
              "      <th>types_pct_B1</th>\n",
              "      <th>types_pct_B2</th>\n",
              "      <th>types_pct_C1</th>\n",
              "      <th>types_pct_C2</th>\n",
              "      <th>is_sparse_cefr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>111</td>\n",
              "      <td>64</td>\n",
              "      <td>0.576577</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>236</td>\n",
              "      <td>165</td>\n",
              "      <td>0.699153</td>\n",
              "      <td>71</td>\n",
              "      <td>32</td>\n",
              "      <td>39</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>0.281818</td>\n",
              "      <td>0.154545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>381</td>\n",
              "      <td>302</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>113</td>\n",
              "      <td>81</td>\n",
              "      <td>44</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.419540</td>\n",
              "      <td>0.235632</td>\n",
              "      <td>0.189655</td>\n",
              "      <td>0.155172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>236</td>\n",
              "      <td>173</td>\n",
              "      <td>0.733051</td>\n",
              "      <td>68</td>\n",
              "      <td>40</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.179191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352113</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.197183</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>265</td>\n",
              "      <td>202</td>\n",
              "      <td>0.762264</td>\n",
              "      <td>99</td>\n",
              "      <td>40</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.491124</td>\n",
              "      <td>0.177515</td>\n",
              "      <td>0.171598</td>\n",
              "      <td>0.159763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "      <td>91</td>\n",
              "      <td>0.834862</td>\n",
              "      <td>44</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.464789</td>\n",
              "      <td>0.239437</td>\n",
              "      <td>0.183099</td>\n",
              "      <td>0.112676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>281</td>\n",
              "      <td>226</td>\n",
              "      <td>0.804270</td>\n",
              "      <td>113</td>\n",
              "      <td>55</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.128319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.435897</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>308</td>\n",
              "      <td>247</td>\n",
              "      <td>0.801948</td>\n",
              "      <td>108</td>\n",
              "      <td>61</td>\n",
              "      <td>46</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129555</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414365</td>\n",
              "      <td>0.254144</td>\n",
              "      <td>0.198895</td>\n",
              "      <td>0.132597</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-569196ea-bf24-4ad9-826c-33f2155fff32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-569196ea-bf24-4ad9-826c-33f2155fff32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-569196ea-bf24-4ad9-826c-33f2155fff32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a0d96848-7ffb-41ee-8e1b-fac1509cc075\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0d96848-7ffb-41ee-8e1b-fac1509cc075')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a0d96848-7ffb-41ee-8e1b-fac1509cc075 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  module_id  total_tokens  known_tokens  known_share  tokens_A1  tokens_A2  \\\n",
              "0         1          7845          6201     0.790440       3061       1271   \n",
              "1         2          6922          5452     0.787634       2476       1205   \n",
              "2         3          7112          5610     0.788808       2469       1302   \n",
              "3         4          7135          5590     0.783462       2649       1129   \n",
              "4         5          7252          5883     0.811224       2526       1337   \n",
              "5         6         22222         17903     0.805643       8010       3948   \n",
              "6       NaN          1248           913     0.731571        363        210   \n",
              "\n",
              "   tokens_B1  tokens_B2  tokens_C1  tokens_C2  ...  tokens_pct_B2  \\\n",
              "0       1043        826          0          0  ...       0.133204   \n",
              "1       1068        703          0          0  ...       0.128944   \n",
              "2       1057        782          0          0  ...       0.139394   \n",
              "3       1087        725          0          0  ...       0.129696   \n",
              "4       1185        835          0          0  ...       0.141934   \n",
              "5       3464       2481          0          0  ...       0.138580   \n",
              "6        170        170          0          0  ...       0.186199   \n",
              "\n",
              "   tokens_pct_C1  tokens_pct_C2  types_pct_A1  types_pct_A2  types_pct_B1  \\\n",
              "0            0.0            0.0      0.458854      0.219108      0.186497   \n",
              "1            0.0            0.0      0.418766      0.241904      0.203709   \n",
              "2            0.0            0.0      0.408957      0.235988      0.204612   \n",
              "3            0.0            0.0      0.437302      0.211640      0.201852   \n",
              "4            0.0            0.0      0.407468      0.235036      0.205107   \n",
              "5            0.0            0.0      0.413727      0.228013      0.206704   \n",
              "6            0.0            0.0      0.386503      0.219325      0.216258   \n",
              "\n",
              "   types_pct_B2  types_pct_C1  types_pct_C2  is_sparse_cefr  \n",
              "0      0.135541           0.0           0.0               0  \n",
              "1      0.135621           0.0           0.0               0  \n",
              "2      0.150442           0.0           0.0               0  \n",
              "3      0.149206           0.0           0.0               0  \n",
              "4      0.152389           0.0           0.0               0  \n",
              "5      0.151556           0.0           0.0               2  \n",
              "6      0.177914           0.0           0.0               2  \n",
              "\n",
              "[7 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa207b33-a967-48ca-ae72-4cf3e4b0e8f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>module_id</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>known_tokens</th>\n",
              "      <th>known_share</th>\n",
              "      <th>tokens_A1</th>\n",
              "      <th>tokens_A2</th>\n",
              "      <th>tokens_B1</th>\n",
              "      <th>tokens_B2</th>\n",
              "      <th>tokens_C1</th>\n",
              "      <th>tokens_C2</th>\n",
              "      <th>...</th>\n",
              "      <th>tokens_pct_B2</th>\n",
              "      <th>tokens_pct_C1</th>\n",
              "      <th>tokens_pct_C2</th>\n",
              "      <th>types_pct_A1</th>\n",
              "      <th>types_pct_A2</th>\n",
              "      <th>types_pct_B1</th>\n",
              "      <th>types_pct_B2</th>\n",
              "      <th>types_pct_C1</th>\n",
              "      <th>types_pct_C2</th>\n",
              "      <th>is_sparse_cefr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7845</td>\n",
              "      <td>6201</td>\n",
              "      <td>0.790440</td>\n",
              "      <td>3061</td>\n",
              "      <td>1271</td>\n",
              "      <td>1043</td>\n",
              "      <td>826</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.133204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458854</td>\n",
              "      <td>0.219108</td>\n",
              "      <td>0.186497</td>\n",
              "      <td>0.135541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>6922</td>\n",
              "      <td>5452</td>\n",
              "      <td>0.787634</td>\n",
              "      <td>2476</td>\n",
              "      <td>1205</td>\n",
              "      <td>1068</td>\n",
              "      <td>703</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.128944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418766</td>\n",
              "      <td>0.241904</td>\n",
              "      <td>0.203709</td>\n",
              "      <td>0.135621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>7112</td>\n",
              "      <td>5610</td>\n",
              "      <td>0.788808</td>\n",
              "      <td>2469</td>\n",
              "      <td>1302</td>\n",
              "      <td>1057</td>\n",
              "      <td>782</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408957</td>\n",
              "      <td>0.235988</td>\n",
              "      <td>0.204612</td>\n",
              "      <td>0.150442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7135</td>\n",
              "      <td>5590</td>\n",
              "      <td>0.783462</td>\n",
              "      <td>2649</td>\n",
              "      <td>1129</td>\n",
              "      <td>1087</td>\n",
              "      <td>725</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.437302</td>\n",
              "      <td>0.211640</td>\n",
              "      <td>0.201852</td>\n",
              "      <td>0.149206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>7252</td>\n",
              "      <td>5883</td>\n",
              "      <td>0.811224</td>\n",
              "      <td>2526</td>\n",
              "      <td>1337</td>\n",
              "      <td>1185</td>\n",
              "      <td>835</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.141934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.407468</td>\n",
              "      <td>0.235036</td>\n",
              "      <td>0.205107</td>\n",
              "      <td>0.152389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>22222</td>\n",
              "      <td>17903</td>\n",
              "      <td>0.805643</td>\n",
              "      <td>8010</td>\n",
              "      <td>3948</td>\n",
              "      <td>3464</td>\n",
              "      <td>2481</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.413727</td>\n",
              "      <td>0.228013</td>\n",
              "      <td>0.206704</td>\n",
              "      <td>0.151556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1248</td>\n",
              "      <td>913</td>\n",
              "      <td>0.731571</td>\n",
              "      <td>363</td>\n",
              "      <td>210</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.186199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386503</td>\n",
              "      <td>0.219325</td>\n",
              "      <td>0.216258</td>\n",
              "      <td>0.177914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa207b33-a967-48ca-ae72-4cf3e4b0e8f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa207b33-a967-48ca-ae72-4cf3e4b0e8f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa207b33-a967-48ca-ae72-4cf3e4b0e8f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-313534bb-c1b3-4183-acfe-ae8e21b62266\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-313534bb-c1b3-4183-acfe-ae8e21b62266')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-313534bb-c1b3-4183-acfe-ae8e21b62266 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 4 — LEVENSHTEIN \"international similarity\" (EN lemma vs RU translation translit)\n",
        "# =========================\n",
        "\n",
        "# Если нужно установить зависимости в Colab — раскомментируй:\n",
        "# !pip -q install python-Levenshtein transliterate deep-translator\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import spacy\n",
        "import Levenshtein\n",
        "from transliterate import translit\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "\n",
        "# ---------- SETTINGS ----------\n",
        "TOP_K = 2500\n",
        "# TOP_K=None  # если хочешь переводить ВСЕ уникальные слова (может быть долго/лимиты)\n",
        "\n",
        "EXCLUDE_STOPWORDS = True\n",
        "BATCH_SIZE = 16\n",
        "SLEEP_SEC = 0.15          # пауза между запросами перевода (бережнее к лимитам)\n",
        "SAVE_EVERY = 200          # как часто сохранять кэш на диск\n",
        "CACHE_PATH = \"lev_translation_cache.csv\"\n",
        "\n",
        "THRESHOLDS = [0.6, 0.7]   # доли \"похожих\" слов\n",
        "\n",
        "# sparse-флаг по страницам (как раньше)\n",
        "MIN_TOKENS_LEV = 50\n",
        "\n",
        "\n",
        "# ---------- NLP INIT ----------\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
        "try:\n",
        "    nlp.max_length = 5_000_000\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "translator = GoogleTranslator(source=\"en\", target=\"ru\")\n",
        "\n",
        "LEMMA_RE = re.compile(r\"^[a-z]+$\")\n",
        "\n",
        "\n",
        "def iter_lemmas(doc):\n",
        "    \"\"\"EN lemmas from spaCy doc.\"\"\"\n",
        "    for token in doc:\n",
        "        if token.is_punct or token.is_space:\n",
        "            continue\n",
        "        if EXCLUDE_STOPWORDS and token.is_stop:\n",
        "            continue\n",
        "        if not token.is_alpha:\n",
        "            continue\n",
        "        lemma = (token.lemma_ or token.text).lower().strip()\n",
        "        if not lemma or not LEMMA_RE.match(lemma):\n",
        "            continue\n",
        "        yield lemma\n",
        "\n",
        "\n",
        "def ru_to_lat_clean(s: str) -> str:\n",
        "    \"\"\"RU -> translit latin + keep only a-z.\"\"\"\n",
        "    s = str(s or \"\").lower()\n",
        "    try:\n",
        "        s = translit(s, \"ru\", reversed=True)\n",
        "    except Exception:\n",
        "        # если внезапно не кириллица / ошибка транслитерации\n",
        "        pass\n",
        "    s = re.sub(r\"[^a-z]\", \"\", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "# ---------- (1) collect lemma counts: global + per page ----------\n",
        "page_meta = [(p.page_num, p.module_id) for p in pages]\n",
        "page_texts = [p.text_en for p in pages]\n",
        "\n",
        "global_freq = Counter()\n",
        "page_freqs = []  # list[Counter]\n",
        "\n",
        "for doc in nlp.pipe(page_texts, batch_size=BATCH_SIZE):\n",
        "    c = Counter(iter_lemmas(doc))\n",
        "    page_freqs.append(c)\n",
        "    global_freq.update(c)\n",
        "\n",
        "print(\"Total unique lemmas:\", len(global_freq))\n",
        "print(\"Total lemma tokens:\", sum(global_freq.values()))\n",
        "\n",
        "\n",
        "# ---------- (2) choose vocab to translate ----------\n",
        "vocab_sorted = [w for w, _ in global_freq.most_common()]  # by frequency\n",
        "if TOP_K is not None:\n",
        "    vocab_to_translate = vocab_sorted[:TOP_K]\n",
        "else:\n",
        "    vocab_to_translate = vocab_sorted\n",
        "\n",
        "print(\"Vocab to translate:\", len(vocab_to_translate))\n",
        "\n",
        "\n",
        "# ---------- (3) load / init translation cache ----------\n",
        "cache = {}\n",
        "if os.path.exists(CACHE_PATH):\n",
        "    try:\n",
        "        df_cache = pd.read_csv(CACHE_PATH)\n",
        "        if {\"word\", \"translation_ru\"}.issubset(df_cache.columns):\n",
        "            cache = dict(zip(df_cache[\"word\"].astype(str), df_cache[\"translation_ru\"].astype(str)))\n",
        "            print(\"Loaded cache:\", len(cache))\n",
        "    except Exception as e:\n",
        "        print(\"Cache load failed:\", e)\n",
        "\n",
        "def save_cache():\n",
        "    df_cache = pd.DataFrame({\"word\": list(cache.keys()), \"translation_ru\": list(cache.values())})\n",
        "    df_cache.to_csv(CACHE_PATH, index=False, encoding=\"utf-8\")\n",
        "\n",
        "# ---------- (4) translate + compute similarity per word ----------\n",
        "rows = []\n",
        "done = 0\n",
        "\n",
        "for w in vocab_to_translate:\n",
        "    if w in cache:\n",
        "        tr = cache[w]\n",
        "    else:\n",
        "        try:\n",
        "            tr = translator.translate(w)\n",
        "        except Exception as e:\n",
        "            tr = \"\"  # пусто = нет перевода/ошибка\n",
        "        cache[w] = tr\n",
        "        time.sleep(SLEEP_SEC)\n",
        "\n",
        "    tr_lat = ru_to_lat_clean(tr)\n",
        "    sim = Levenshtein.ratio(w, tr_lat) if tr_lat else np.nan\n",
        "\n",
        "    rows.append({\n",
        "        \"word\": w,\n",
        "        \"frequency\": int(global_freq[w]),\n",
        "        \"translation_ru\": tr,\n",
        "        \"translation_lat\": tr_lat,\n",
        "        \"similarity\": sim\n",
        "    })\n",
        "\n",
        "    done += 1\n",
        "    if done % SAVE_EVERY == 0:\n",
        "        save_cache()\n",
        "        print(\"...saved cache\", done)\n",
        "\n",
        "# финальное сохранение кэша\n",
        "save_cache()\n",
        "\n",
        "df_lev_words = pd.DataFrame(rows)\n",
        "df_lev_words = df_lev_words.sort_values([\"frequency\"], ascending=False).reset_index(drop=True)\n",
        "\n",
        "display(df_lev_words.head(20))\n",
        "print(\"Mean similarity (unweighted):\", float(df_lev_words[\"similarity\"].mean()))\n",
        "\n",
        "\n",
        "# ---------- (5) similarity map for aggregations ----------\n",
        "sim_map = dict(zip(df_lev_words[\"word\"], df_lev_words[\"similarity\"]))\n",
        "\n",
        "def weighted_mean_similarity(counter: Counter) -> float:\n",
        "    num = 0.0\n",
        "    den = 0\n",
        "    for w, cnt in counter.items():\n",
        "        sim = sim_map.get(w, np.nan)\n",
        "        if sim is None or np.isnan(sim):\n",
        "            continue\n",
        "        num += sim * cnt\n",
        "        den += cnt\n",
        "    return (num / den) if den else np.nan\n",
        "\n",
        "def token_share_above(counter: Counter, thr: float) -> float:\n",
        "    num = 0\n",
        "    den = 0\n",
        "    for w, cnt in counter.items():\n",
        "        sim = sim_map.get(w, np.nan)\n",
        "        if sim is None or np.isnan(sim):\n",
        "            continue\n",
        "        den += cnt\n",
        "        if sim >= thr:\n",
        "            num += cnt\n",
        "    return (num / den) if den else np.nan\n",
        "\n",
        "def type_share_above(counter: Counter, thr: float) -> float:\n",
        "    words = [w for w in counter.keys() if not np.isnan(sim_map.get(w, np.nan))]\n",
        "    if not words:\n",
        "        return np.nan\n",
        "    good = sum(1 for w in words if sim_map.get(w, np.nan) >= thr)\n",
        "    return good / len(words)\n",
        "\n",
        "\n",
        "# ---------- (6) by page ----------\n",
        "by_page_rows = []\n",
        "for (page_num, module_id), c in zip(page_meta, page_freqs):\n",
        "    total_tokens = int(sum(c.values()))\n",
        "    mean_w = weighted_mean_similarity(c)\n",
        "\n",
        "    row = {\n",
        "        \"page_num\": page_num,\n",
        "        \"module_id\": module_id,\n",
        "        \"total_tokens\": total_tokens,\n",
        "        \"lev_mean_weighted\": mean_w,\n",
        "        \"is_sparse_lev\": total_tokens < MIN_TOKENS_LEV\n",
        "    }\n",
        "    for thr in THRESHOLDS:\n",
        "        row[f\"token_share_ge_{thr}\"] = token_share_above(c, thr)\n",
        "        row[f\"type_share_ge_{thr}\"] = type_share_above(c, thr)\n",
        "    by_page_rows.append(row)\n",
        "\n",
        "df_lev_by_page = pd.DataFrame(by_page_rows).sort_values(\"page_num\").reset_index(drop=True)\n",
        "display(df_lev_by_page.head(10))\n",
        "\n",
        "\n",
        "# ---------- (7) by module ----------\n",
        "module_counters = defaultdict(Counter)\n",
        "for (page_num, module_id), c in zip(page_meta, page_freqs):\n",
        "    module_counters[module_id].update(c)\n",
        "\n",
        "by_module_rows = []\n",
        "for module_id, c in module_counters.items():\n",
        "    total_tokens = int(sum(c.values()))\n",
        "    row = {\n",
        "        \"module_id\": module_id,\n",
        "        \"total_tokens\": total_tokens,\n",
        "        \"lev_mean_weighted\": weighted_mean_similarity(c),\n",
        "    }\n",
        "    for thr in THRESHOLDS:\n",
        "        row[f\"token_share_ge_{thr}\"] = token_share_above(c, thr)\n",
        "        row[f\"type_share_ge_{thr}\"] = type_share_above(c, thr)\n",
        "    by_module_rows.append(row)\n",
        "\n",
        "df_lev_by_module = pd.DataFrame(by_module_rows).sort_values(\"module_id\").reset_index(drop=True)\n",
        "display(df_lev_by_module.head(20))\n",
        "\n",
        "\n",
        "# ---------- (8) Save outputs ----------\n",
        "df_lev_words.to_csv(\"lev_words_table.csv\", index=False, encoding=\"utf-8\")\n",
        "df_lev_by_page.to_csv(\"lev_by_page.csv\", index=False, encoding=\"utf-8\")\n",
        "df_lev_by_module.to_csv(\"lev_by_module.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "with pd.ExcelWriter(\"lev_outputs.xlsx\") as w:\n",
        "    df_lev_words.to_excel(w, sheet_name=\"word_table\", index=False)\n",
        "    df_lev_by_page.to_excel(w, sheet_name=\"by_page\", index=False)\n",
        "    df_lev_by_module.to_excel(w, sheet_name=\"by_module\", index=False)\n",
        "\n",
        "print(\"OK -> lev_outputs.xlsx + lev_words_table.csv / lev_by_page.csv / lev_by_module.csv\")\n",
        "print(\"Cache saved ->\", CACHE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "mKu_3ogkWCOu",
        "outputId": "ff7bd162-92ee-4424-fce8-61091399c3ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique lemmas: 6660\n",
            "Total lemma tokens: 59736\n",
            "Vocab to translate: 2500\n",
            "...saved cache 200\n",
            "...saved cache 400\n",
            "...saved cache 600\n",
            "...saved cache 800\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3090506993.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m  \u001b[0;31m# пусто = нет перевода/ошибка\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSLEEP_SEC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtr_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mru_to_lat_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL 3.1 — EXERCISE BLOCKS (better extraction for RU textbooks)\n",
        "# =========================\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------\n",
        "# Heuristics dictionaries\n",
        "# -------------------------\n",
        "\n",
        "# Частые \"служебные/мусорные\" строки (титул, выходные данные, оглавление, копирайты)\n",
        "FILTER_PATTERNS = [\n",
        "    r\"^\\s*(удк|ббк)\\b\",\n",
        "    r\"\\bISBN\\b\",\n",
        "    r\"^\\s*©\",\n",
        "    r\"\\bExpress Publishing\\b\",\n",
        "    r\"\\bPROSVESHCHENIYE\\b\",\n",
        "    r\"\\bPUBLISHERS\\b\",\n",
        "    r\"^\\s*Отпечатано\\b\",\n",
        "    r\"^\\s*Подписано в печать\\b\",\n",
        "    r\"^\\s*Тираж\\b\",\n",
        "    r\"^\\s*Заказ\\b\",\n",
        "    r\"\\bhttp[s]?://\\S+\",\n",
        "    r\"\\bwww\\.\\S+\",\n",
        "    r\"\\be-mail\\b\",\n",
        "    r\"^\\s*Contents\\b\",\n",
        "    r\"^\\s*Содержание\\b\",\n",
        "    r\"^\\s*Authors?\\b\",\n",
        "    r\"^\\s*Acknowledgements?\\b\",\n",
        "]\n",
        "\n",
        "# Заголовки-разделители (не упражнение)\n",
        "SECTION_PATTERNS = [\n",
        "    r\"^\\s*(Module|MODULE)\\s+\\d+\\b\",\n",
        "    r\"^\\s*(Starter module|STARTER MODULE)\\b\",\n",
        "    r\"^\\s*(Vocabulary|VOCABULARY)\\b\",\n",
        "    r\"^\\s*(Grammar|GRAMMAR)\\b\",\n",
        "    r\"^\\s*(Everyday English|EVERYDAY ENGLISH)\\b\",\n",
        "    r\"^\\s*(Study skills|STUDY SKILLS)\\b\",\n",
        "    r\"^\\s*(Writing|WRITING)\\b\",\n",
        "    r\"^\\s*(Reading|READING)\\b\",\n",
        "    r\"^\\s*(Listening|LISTENING)\\b\",\n",
        "    r\"^\\s*(Speaking|SPEAKING)\\b\",\n",
        "    r\"^\\s*(Culture Corner|CULTURE CORNER)\\b\",\n",
        "    r\"^\\s*(Revision|REVISION)\\b\",\n",
        "    r\"^\\s*(Word List|WORD LIST)\\b\",\n",
        "    r\"^\\s*(Irregular Verbs|IRREGULAR VERBS)\\b\",\n",
        "    r\"^\\s*(Vocabulary Bank|VOCABULARY BANK)\\b\",\n",
        "    r\"^\\s*(Writing Bank|WRITING BANK)\\b\",\n",
        "    r\"^\\s*(Grammar Reference|GRAMMAR REFERENCE)\\b\",\n",
        "    r\"^\\s*(Use of English|USE OF ENGLISH)\\b\",\n",
        "]\n",
        "\n",
        "# Императивы RU/EN (для коротких инструкций)\n",
        "RU_IMP = [\n",
        "    \"прочитай\", \"прочтите\", \"послушай\", \"послушайте\", \"сделай\", \"сделайте\",\n",
        "    \"выполни\", \"выполните\", \"выбери\", \"выберите\", \"вставь\", \"вставьте\",\n",
        "    \"заполни\", \"заполните\", \"соедини\", \"соедините\", \"сопоставь\", \"сопоставьте\",\n",
        "    \"ответь\", \"ответьте\", \"обсуди\", \"обсудите\", \"скажи\", \"скажите\", \"напиши\",\n",
        "    \"напишите\", \"составь\", \"составьте\", \"переведи\", \"переведите\", \"найди\", \"найдите\",\n",
        "    \"подчеркни\", \"подчеркните\", \"распредели\", \"распределите\", \"поставь\", \"поставьте\",\n",
        "    \"отметь\", \"отметьте\", \"догадайся\", \"догадайтесь\", \"закончи\", \"закончите\",\n",
        "    \"раскрой\", \"раскройте\", \"определи\", \"определите\"\n",
        "]\n",
        "\n",
        "EN_IMP = [\n",
        "    \"read\", \"listen\", \"match\", \"choose\", \"complete\", \"fill\", \"write\", \"answer\",\n",
        "    \"discuss\", \"look\", \"find\", \"say\", \"talk\", \"check\", \"circle\", \"underline\"\n",
        "]\n",
        "\n",
        "RU_IMP_RE = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, RU_IMP)) + r\")\\b\", re.IGNORECASE)\n",
        "EN_IMP_RE = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, EN_IMP)) + r\")\\b\", re.IGNORECASE)\n",
        "\n",
        "FILTER_RE = re.compile(\"|\".join(FILTER_PATTERNS), re.IGNORECASE)\n",
        "SECTION_RE = re.compile(\"|\".join(SECTION_PATTERNS), re.IGNORECASE)\n",
        "\n",
        "# -------------------------\n",
        "# Low-level helpers\n",
        "# -------------------------\n",
        "\n",
        "def is_filtered_line(line: str) -> bool:\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return True\n",
        "    # одиночные номера страниц / мусор\n",
        "    if re.fullmatch(r\"\\d{1,4}\", t):\n",
        "        return True\n",
        "    return bool(FILTER_RE.search(t))\n",
        "\n",
        "def is_section_heading(line: str) -> bool:\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return False\n",
        "    # капс-заголовки (часто разделители)\n",
        "    letters = re.sub(r\"[^A-Za-zА-Яа-яЁё]\", \"\", t)\n",
        "    if letters and sum(ch.isupper() for ch in letters) / max(len(letters), 1) > 0.9 and len(letters) >= 8:\n",
        "        return True\n",
        "    return bool(SECTION_RE.search(t))\n",
        "\n",
        "def latin_ratio(line: str) -> float:\n",
        "    letters = re.findall(r\"[A-Za-zА-Яа-яЁё]\", line or \"\")\n",
        "    if not letters:\n",
        "        return 0.0\n",
        "    lat = sum(1 for ch in letters if \"A\" <= ch <= \"Z\" or \"a\" <= ch <= \"z\")\n",
        "    return lat / len(letters)\n",
        "\n",
        "def looks_like_wordlist(line: str) -> bool:\n",
        "    \"\"\"\n",
        "    Частые \"Vocabulary lists\":\n",
        "    - почти вся строка латиница\n",
        "    - много разделителей ; , •\n",
        "    - мало глагольных инструкций\n",
        "    \"\"\"\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return False\n",
        "    if latin_ratio(t) < 0.85:\n",
        "        return False\n",
        "    if (t.count(\",\") + t.count(\";\") + t.count(\"•\")) >= 3 and not EN_IMP_RE.search(t):\n",
        "        return True\n",
        "    # просто набор слов\n",
        "    if len(t.split()) >= 6 and not EN_IMP_RE.search(t) and not re.search(r\"[.!?]$\", t):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_numbered_task(line: str) -> bool:\n",
        "    \"\"\"\n",
        "    Старт задания:\n",
        "      1) ...\n",
        "      1. ...\n",
        "      1 ...\n",
        "      12 a) ...\n",
        "      Ex. 3 ...\n",
        "    + защита от \"pp. 7-21\" и годов/выходных данных\n",
        "    \"\"\"\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return False\n",
        "\n",
        "    # исключим \"pp. 7-21\", \"p. 26\"\n",
        "    if re.search(r\"\\bpp?\\.\\s*\\d\", t, re.IGNORECASE):\n",
        "        return False\n",
        "\n",
        "    # Ex. 1 / Exercise 1\n",
        "    if re.match(r\"^(?:ex\\.?|exercise)\\s*\\d+\\b\", t, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    m = re.match(r\"^(\\d{1,2})(?:\\s*[.)]|)\\s+(\\S.*)$\", t)\n",
        "    if not m:\n",
        "        return False\n",
        "\n",
        "    n = int(m.group(1))\n",
        "    # разумные номера упражнений, чтобы не ловить 2013/127521 и т.п.\n",
        "    if not (1 <= n <= 50):\n",
        "        return False\n",
        "\n",
        "    tail = m.group(2)\n",
        "    # если хвост выглядит как \"pp. 7-21\" — уже отрезали; доп. защита:\n",
        "    if re.match(r\"^\\d+[-–]\\d+$\", tail):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def is_short_instruction(line: str) -> bool:\n",
        "    t = (line or \"\").strip()\n",
        "    if not t:\n",
        "        return False\n",
        "    if len(t) > 120:\n",
        "        return False\n",
        "    if looks_like_wordlist(t):\n",
        "        return False\n",
        "    return bool(RU_IMP_RE.search(t) or EN_IMP_RE.search(t))\n",
        "\n",
        "def has_numbered_nearby(lines: list[str], i: int, window: int = 2) -> bool:\n",
        "    for j in range(i + 1, min(len(lines), i + 1 + window)):\n",
        "        tj = (lines[j] or \"\").strip()\n",
        "        if not tj:\n",
        "            continue\n",
        "        if is_numbered_task(tj):\n",
        "            return True\n",
        "        # если встретили крупный заголовок — дальше не смотрим\n",
        "        if is_section_heading(tj) or is_filtered_line(tj):\n",
        "            break\n",
        "    return False\n",
        "\n",
        "def strip_task_prefix(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    s = re.sub(r\"^(?:ex\\.?|exercise)\\s*\\d+\\s*\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"^\\d{1,2}\\s*[.)]?\\s*\", \"\", s)  # 1) / 1. / 1\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def to_ru_layer(s: str) -> str:\n",
        "    # оставляем кириллицу+цифры+пунктуацию\n",
        "    tokens = re.findall(r\"[А-Яа-яЁё]+(?:-[А-Яа-яЁё]+)?|[0-9]+|[.!?,;:\\-—()\\[\\]\\\"“”'…]+\", s or \"\")\n",
        "    out = \" \".join(tokens)\n",
        "    out = re.sub(r\"\\s+([.!?,;:])\", r\"\\1\", out)\n",
        "    return out.strip()\n",
        "\n",
        "def to_en_layer(s: str) -> str:\n",
        "    tokens = re.findall(r\"[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+|[.!?,;:\\-—()\\[\\]\\\"“”'…]+\", s or \"\")\n",
        "    out = \" \".join(tokens)\n",
        "    out = re.sub(r\"\\s+([.!?,;:])\", r\"\\1\", out)\n",
        "    return out.strip()\n",
        "\n",
        "# -------------------------\n",
        "# Core extraction per page\n",
        "# -------------------------\n",
        "\n",
        "def extract_exercise_blocks_from_page(text_clean: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    State machine:\n",
        "    - фильтруем мусорные строки\n",
        "    - section headings режут поток\n",
        "    - старт задания: numbered OR short-instruction рядом с numbered OR в exercise_mode\n",
        "    \"\"\"\n",
        "    lines_raw = (text_clean or \"\").splitlines()\n",
        "    # сохраним пустые строки как границы, но \"мусорные\" удалим\n",
        "    lines = []\n",
        "    for ln in lines_raw:\n",
        "        t = ln.rstrip()\n",
        "        if not t.strip():\n",
        "            lines.append(\"\")  # граница\n",
        "            continue\n",
        "        if is_filtered_line(t):\n",
        "            continue\n",
        "        lines.append(t)\n",
        "\n",
        "    blocks = []\n",
        "    cur = []\n",
        "    exercise_mode = False\n",
        "    started_reason = None\n",
        "\n",
        "    def flush():\n",
        "        nonlocal cur, started_reason\n",
        "        text = \"\\n\".join([x for x in cur if x != \"\"]).strip()\n",
        "        if text:\n",
        "            blocks.append({\"block_text\": text, \"start_reason\": started_reason or \"\"})\n",
        "        cur = []\n",
        "        started_reason = None\n",
        "\n",
        "    for i, ln in enumerate(lines):\n",
        "        t = (ln or \"\").strip()\n",
        "\n",
        "        # границы абзацев не всегда конец блока — но если блок большой, можно завершить по двойной пустоте\n",
        "        if t == \"\":\n",
        "            # оставляем пустую строку внутри блока максимум как разделитель\n",
        "            if cur and (len(cur) == 0 or cur[-1] != \"\"):\n",
        "                cur.append(\"\")\n",
        "            continue\n",
        "\n",
        "        # section heading — всегда граница режима\n",
        "        if is_section_heading(t):\n",
        "            flush()\n",
        "            exercise_mode = False\n",
        "            continue\n",
        "\n",
        "        # старт задания\n",
        "        start = False\n",
        "        if is_numbered_task(t):\n",
        "            start = True\n",
        "            started_reason = \"numbered_task\"\n",
        "        else:\n",
        "            # короткая инструкция как старт — только если рядом есть numbered или мы уже в режиме упражнений\n",
        "            if is_short_instruction(t) and (exercise_mode or has_numbered_nearby(lines, i, window=2)):\n",
        "                start = True\n",
        "                started_reason = \"short_instruction_near_numbered\" if not exercise_mode else \"short_instruction_in_mode\"\n",
        "\n",
        "        if start:\n",
        "            flush()\n",
        "            exercise_mode = True\n",
        "            cur.append(t)\n",
        "        else:\n",
        "            # если не в режиме упражнений — пропускаем всё, что похоже на wordlist/оглавление\n",
        "            if not exercise_mode:\n",
        "                if looks_like_wordlist(t):\n",
        "                    continue\n",
        "                # иногда “Vocabulary” списки без заголовка — тоже игнорим\n",
        "                if latin_ratio(t) > 0.9 and not EN_IMP_RE.search(t) and len(t.split()) >= 6:\n",
        "                    continue\n",
        "            # если в режиме — накапливаем\n",
        "            if exercise_mode:\n",
        "                cur.append(t)\n",
        "\n",
        "    flush()\n",
        "    return blocks\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Build ex_df for ALL pages\n",
        "# -------------------------\n",
        "\n",
        "rows = []\n",
        "ex_id = 0\n",
        "\n",
        "for p in pages:\n",
        "    page_blocks = extract_exercise_blocks_from_page(p.text_clean)\n",
        "\n",
        "    for b_i, b in enumerate(page_blocks, start=1):\n",
        "        block_text = b[\"block_text\"]\n",
        "\n",
        "        # инструкция: первая непустая строка блока (подрезаем префиксы \"1) \")\n",
        "        first_line = next((x.strip() for x in block_text.splitlines() if x.strip()), \"\")\n",
        "        instr_raw = strip_task_prefix(first_line)\n",
        "\n",
        "        # если инструкция совсем пустая — пропускаем\n",
        "        if not instr_raw or len(instr_raw) < 6:\n",
        "            continue\n",
        "\n",
        "        # слои\n",
        "        instr_ru = to_ru_layer(instr_raw)\n",
        "        instr_en = to_en_layer(instr_raw)\n",
        "\n",
        "        # \"best\" — если кириллицы много, берем RU, иначе EN\n",
        "        best = instr_ru if len(re.findall(r\"[А-Яа-яЁё]\", instr_ru)) >= 3 else instr_en\n",
        "\n",
        "        ex_id += 1\n",
        "        rows.append({\n",
        "            \"exercise_id\": ex_id,\n",
        "            \"page_num\": p.page_num,\n",
        "            \"module_id\": p.module_id,\n",
        "            \"block_local_id\": b_i,\n",
        "            \"start_reason\": b.get(\"start_reason\", \"\"),\n",
        "            \"instruction_raw\": instr_raw,\n",
        "            \"instruction_ru\": instr_ru,\n",
        "            \"instruction_en\": instr_en,\n",
        "            \"instruction_best\": best,\n",
        "            \"block_text\": block_text,\n",
        "        })\n",
        "\n",
        "ex_df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"Extracted exercise blocks:\", len(ex_df))\n",
        "display(ex_df.head(15))\n",
        "\n",
        "# Сохраним для дебага\n",
        "ex_df.to_excel(\"exercise_blocks_extracted.xlsx\", index=False)\n",
        "print(\"OK -> exercise_blocks_extracted.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YQr22JL1gxsR",
        "outputId": "ec509881-06a3-450c-cac4-a880875097bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted exercise blocks: 2704\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    exercise_id  page_num module_id  block_local_id  \\\n",
              "0             1         6      None               1   \n",
              "1             2         6      None               2   \n",
              "2             3         6      None               3   \n",
              "3             4         6      None               4   \n",
              "4             5         6      None               5   \n",
              "5             6         6      None               6   \n",
              "6             7         6      None               7   \n",
              "7             8         6      None               8   \n",
              "8             9         6      None               9   \n",
              "9            10         6      None              10   \n",
              "10           11         6      None              11   \n",
              "11           12         6      None              12   \n",
              "12           13         6      None              13   \n",
              "13           14         6      None              14   \n",
              "14           15         6      None              15   \n",
              "\n",
              "                 start_reason  \\\n",
              "0               numbered_task   \n",
              "1   short_instruction_in_mode   \n",
              "2               numbered_task   \n",
              "3   short_instruction_in_mode   \n",
              "4               numbered_task   \n",
              "5               numbered_task   \n",
              "6               numbered_task   \n",
              "7               numbered_task   \n",
              "8               numbered_task   \n",
              "9               numbered_task   \n",
              "10  short_instruction_in_mode   \n",
              "11              numbered_task   \n",
              "12              numbered_task   \n",
              "13              numbered_task   \n",
              "14              numbered_task   \n",
              "\n",
              "                                      instruction_raw  \\\n",
              "0         Shopping 4 Match the words to form phrases.   \n",
              "1   designer A conditions 2 recycled B prices 3 wo...   \n",
              "2                 Shops 2 Write the name of the shop.   \n",
              "3   It sells boots and sandals. s ___ s ___ 2 You ...   \n",
              "4          Faulty products 3 Choose the correct word.   \n",
              "5   I can’t carry the bag. The strap is broken/inj...   \n",
              "6   I need to have the lens replaced. It is scratc...   \n",
              "7     Don’t use this teapot. The lid is cracked/torn.   \n",
              "8   Don’t drink from this mug. There’s a hole/chip...   \n",
              "9   I can’t wear my sandals. The heels are cracked...   \n",
              "10  Don’t wear this shirt. One button is missing/d...   \n",
              "11  Social issues 5 Fill in: donate, volunteer, jo...   \n",
              "12  We should all help ___ the quality of life in ...   \n",
              "13  Don’t throw away things you don’t need. ___ th...   \n",
              "14            ___ the litter you threw on the street.   \n",
              "\n",
              "                               instruction_ru  \\\n",
              "0                                          4.   \n",
              "1                               2 3 4 5 6 7 8   \n",
              "2                                          2.   \n",
              "3   . 2. 3. ' 4. ' 5. 6. ' 7. ' 8. ' 9. ' 10.   \n",
              "4                                          3.   \n",
              "5                                          ..   \n",
              "6                                          ..   \n",
              "7                                          ..   \n",
              "8                                          ..   \n",
              "9                                          ..   \n",
              "10                                         ..   \n",
              "11                                   5:,,,,,.   \n",
              "12                                          .   \n",
              "13                                         ..   \n",
              "14                                          .   \n",
              "\n",
              "                                       instruction_en  \\\n",
              "0         Shopping 4 Match the words to form phrases.   \n",
              "1   designer A conditions 2 recycled B prices 3 wo...   \n",
              "2                 Shops 2 Write the name of the shop.   \n",
              "3   It sells boots and sandals. s s 2 You can find...   \n",
              "4          Faulty products 3 Choose the correct word.   \n",
              "5   I can t carry the bag. The strap is broken inj...   \n",
              "6   I need to have the lens replaced. It is scratc...   \n",
              "7     Don t use this teapot. The lid is cracked torn.   \n",
              "8   Don t drink from this mug. There s a hole chip...   \n",
              "9   I can t wear my sandals. The heels are cracked...   \n",
              "10  Don t wear this shirt. One button is missing d...   \n",
              "11  Social issues 5 Fill in: donate, volunteer, jo...   \n",
              "12  We should all help the quality of life in our ...   \n",
              "13  Don t throw away things you don t need. them t...   \n",
              "14                the litter you threw on the street.   \n",
              "\n",
              "                                     instruction_best  \\\n",
              "0         Shopping 4 Match the words to form phrases.   \n",
              "1   designer A conditions 2 recycled B prices 3 wo...   \n",
              "2                 Shops 2 Write the name of the shop.   \n",
              "3   It sells boots and sandals. s s 2 You can find...   \n",
              "4          Faulty products 3 Choose the correct word.   \n",
              "5   I can t carry the bag. The strap is broken inj...   \n",
              "6   I need to have the lens replaced. It is scratc...   \n",
              "7     Don t use this teapot. The lid is cracked torn.   \n",
              "8   Don t drink from this mug. There s a hole chip...   \n",
              "9   I can t wear my sandals. The heels are cracked...   \n",
              "10  Don t wear this shirt. One button is missing d...   \n",
              "11  Social issues 5 Fill in: donate, volunteer, jo...   \n",
              "12  We should all help the quality of life in our ...   \n",
              "13  Don t throw away things you don t need. them t...   \n",
              "14                the litter you threw on the street.   \n",
              "\n",
              "                                           block_text  \n",
              "0         Shopping 4 Match the words to form phrases.  \n",
              "1   1 designer A conditions 2 recycled B prices 3 ...  \n",
              "2                 Shops 2 Write the name of the shop.  \n",
              "3   1 It sells boots and sandals. s ___ s ___ 2 Yo...  \n",
              "4          Faulty products 3 Choose the correct word.  \n",
              "5   1 I can’t carry the bag. The strap is broken/i...  \n",
              "6   2 I need to have the lens replaced. It is scra...  \n",
              "7   3 Don’t use this teapot. The lid is cracked/torn.  \n",
              "8   4 Don’t drink from this mug. There’s a hole/ch...  \n",
              "9   5 I can’t wear my sandals. The heels are crack...  \n",
              "10  6 Don’t wear this shirt. One button is missing...  \n",
              "11  Social issues 5 Fill in: donate, volunteer, jo...  \n",
              "12  1 We should all help ___ the quality of life i...  \n",
              "13  2 Don’t throw away things you don’t need. ___ ...  \n",
              "14          3 ___ the litter you threw on the street.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1dd9b57-d011-45be-9425-f7f2d8e56638\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exercise_id</th>\n",
              "      <th>page_num</th>\n",
              "      <th>module_id</th>\n",
              "      <th>block_local_id</th>\n",
              "      <th>start_reason</th>\n",
              "      <th>instruction_raw</th>\n",
              "      <th>instruction_ru</th>\n",
              "      <th>instruction_en</th>\n",
              "      <th>instruction_best</th>\n",
              "      <th>block_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Shopping 4 Match the words to form phrases.</td>\n",
              "      <td>4.</td>\n",
              "      <td>Shopping 4 Match the words to form phrases.</td>\n",
              "      <td>Shopping 4 Match the words to form phrases.</td>\n",
              "      <td>Shopping 4 Match the words to form phrases.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>2</td>\n",
              "      <td>short_instruction_in_mode</td>\n",
              "      <td>designer A conditions 2 recycled B prices 3 wo...</td>\n",
              "      <td>2 3 4 5 6 7 8</td>\n",
              "      <td>designer A conditions 2 recycled B prices 3 wo...</td>\n",
              "      <td>designer A conditions 2 recycled B prices 3 wo...</td>\n",
              "      <td>1 designer A conditions 2 recycled B prices 3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Shops 2 Write the name of the shop.</td>\n",
              "      <td>2.</td>\n",
              "      <td>Shops 2 Write the name of the shop.</td>\n",
              "      <td>Shops 2 Write the name of the shop.</td>\n",
              "      <td>Shops 2 Write the name of the shop.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>4</td>\n",
              "      <td>short_instruction_in_mode</td>\n",
              "      <td>It sells boots and sandals. s ___ s ___ 2 You ...</td>\n",
              "      <td>. 2. 3. ' 4. ' 5. 6. ' 7. ' 8. ' 9. ' 10.</td>\n",
              "      <td>It sells boots and sandals. s s 2 You can find...</td>\n",
              "      <td>It sells boots and sandals. s s 2 You can find...</td>\n",
              "      <td>1 It sells boots and sandals. s ___ s ___ 2 Yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Faulty products 3 Choose the correct word.</td>\n",
              "      <td>3.</td>\n",
              "      <td>Faulty products 3 Choose the correct word.</td>\n",
              "      <td>Faulty products 3 Choose the correct word.</td>\n",
              "      <td>Faulty products 3 Choose the correct word.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>6</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>I can’t carry the bag. The strap is broken/inj...</td>\n",
              "      <td>..</td>\n",
              "      <td>I can t carry the bag. The strap is broken inj...</td>\n",
              "      <td>I can t carry the bag. The strap is broken inj...</td>\n",
              "      <td>1 I can’t carry the bag. The strap is broken/i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>I need to have the lens replaced. It is scratc...</td>\n",
              "      <td>..</td>\n",
              "      <td>I need to have the lens replaced. It is scratc...</td>\n",
              "      <td>I need to have the lens replaced. It is scratc...</td>\n",
              "      <td>2 I need to have the lens replaced. It is scra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Don’t use this teapot. The lid is cracked/torn.</td>\n",
              "      <td>..</td>\n",
              "      <td>Don t use this teapot. The lid is cracked torn.</td>\n",
              "      <td>Don t use this teapot. The lid is cracked torn.</td>\n",
              "      <td>3 Don’t use this teapot. The lid is cracked/torn.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>9</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Don’t drink from this mug. There’s a hole/chip...</td>\n",
              "      <td>..</td>\n",
              "      <td>Don t drink from this mug. There s a hole chip...</td>\n",
              "      <td>Don t drink from this mug. There s a hole chip...</td>\n",
              "      <td>4 Don’t drink from this mug. There’s a hole/ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>10</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>I can’t wear my sandals. The heels are cracked...</td>\n",
              "      <td>..</td>\n",
              "      <td>I can t wear my sandals. The heels are cracked...</td>\n",
              "      <td>I can t wear my sandals. The heels are cracked...</td>\n",
              "      <td>5 I can’t wear my sandals. The heels are crack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>11</td>\n",
              "      <td>short_instruction_in_mode</td>\n",
              "      <td>Don’t wear this shirt. One button is missing/d...</td>\n",
              "      <td>..</td>\n",
              "      <td>Don t wear this shirt. One button is missing d...</td>\n",
              "      <td>Don t wear this shirt. One button is missing d...</td>\n",
              "      <td>6 Don’t wear this shirt. One button is missing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>12</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Social issues 5 Fill in: donate, volunteer, jo...</td>\n",
              "      <td>5:,,,,,.</td>\n",
              "      <td>Social issues 5 Fill in: donate, volunteer, jo...</td>\n",
              "      <td>Social issues 5 Fill in: donate, volunteer, jo...</td>\n",
              "      <td>Social issues 5 Fill in: donate, volunteer, jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>13</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>We should all help ___ the quality of life in ...</td>\n",
              "      <td>.</td>\n",
              "      <td>We should all help the quality of life in our ...</td>\n",
              "      <td>We should all help the quality of life in our ...</td>\n",
              "      <td>1 We should all help ___ the quality of life i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>14</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>Don’t throw away things you don’t need. ___ th...</td>\n",
              "      <td>..</td>\n",
              "      <td>Don t throw away things you don t need. them t...</td>\n",
              "      <td>Don t throw away things you don t need. them t...</td>\n",
              "      <td>2 Don’t throw away things you don’t need. ___ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>15</td>\n",
              "      <td>numbered_task</td>\n",
              "      <td>___ the litter you threw on the street.</td>\n",
              "      <td>.</td>\n",
              "      <td>the litter you threw on the street.</td>\n",
              "      <td>the litter you threw on the street.</td>\n",
              "      <td>3 ___ the litter you threw on the street.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1dd9b57-d011-45be-9425-f7f2d8e56638')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1dd9b57-d011-45be-9425-f7f2d8e56638 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1dd9b57-d011-45be-9425-f7f2d8e56638');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-57ab3e1d-a9fa-4008-a447-c03b56c9511c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57ab3e1d-a9fa-4008-a447-c03b56c9511c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-57ab3e1d-a9fa-4008-a447-c03b56c9511c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK -> exercise_blocks_extracted.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Автоматическая обработка**"
      ],
      "metadata": {
        "id": "NhHmVSiGBymg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ВАЖНО: путь должен 1-в-1 совпадать с именами папок в MyDrive\n",
        "ROOT_DIR = \"/content/drive/MyDrive/EduText Analyzer/Учебники TXT\"\n",
        "\n",
        "import os\n",
        "print(\"ROOT exists:\", os.path.exists(ROOT_DIR))\n",
        "print(\"Subfolders:\", os.listdir(ROOT_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6tb1j4oB5NK",
        "outputId": "3d95e047-a892-4431-d56a-28785a1eab94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ROOT exists: True\n",
            "Subfolders: ['spotlight-txt', 'starlight-txt', 'books_manifest.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def slugify(s: str) -> str:\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"\\.txt$\", \"\", s)\n",
        "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s\n",
        "\n",
        "def infer_series_from_parent(p: Path) -> str:\n",
        "    # spotlight-txt -> spotlight\n",
        "    return p.parent.name.replace(\"-txt\", \"\").strip()\n",
        "\n",
        "def infer_grade_from_name(name: str):\n",
        "    # spotlight-2.txt -> 2\n",
        "    # starlight-2-1.txt -> 2 (первое число)\n",
        "    m = re.search(r\"(\\d{1,2})\", name)\n",
        "    return int(m.group(1)) if m else \"\"\n",
        "\n",
        "def infer_title(series: str, grade, filename: str) -> str:\n",
        "    if grade != \"\":\n",
        "        return f\"{series.title()} {grade}\"\n",
        "    # если не нашли класс — просто имя файла\n",
        "    return filename.replace(\".txt\", \"\")\n",
        "\n",
        "def detect_lang_quick(text: str) -> str:\n",
        "    # грубая эвристика: по доле кириллицы/латиницы в сэмпле\n",
        "    sample = (text or \"\")[:20000]\n",
        "    cyr = len(re.findall(r\"[А-Яа-яЁё]\", sample))\n",
        "    lat = len(re.findall(r\"[A-Za-z]\", sample))\n",
        "    total = cyr + lat\n",
        "    if total == 0:\n",
        "        return \"\"\n",
        "    cyr_ratio = cyr / total\n",
        "    lat_ratio = lat / total\n",
        "    if cyr_ratio > 0.7:\n",
        "        return \"ru\"\n",
        "    if lat_ratio > 0.7:\n",
        "        return \"en\"\n",
        "    return \"mixed\"\n",
        "\n",
        "txt_files = sorted(Path(ROOT_DIR).rglob(\"*.txt\"))\n",
        "print(\"Found txt files:\", len(txt_files))\n",
        "print(\"Example:\", txt_files[:3])\n",
        "\n",
        "rows = []\n",
        "for p in txt_files:\n",
        "    series = infer_series_from_parent(p)\n",
        "    grade = infer_grade_from_name(p.name)\n",
        "    title = infer_title(series, grade, p.name)\n",
        "\n",
        "    # быстрый детект языка по первым 20k символов\n",
        "    try:\n",
        "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "            lang = detect_lang_quick(f.read())\n",
        "    except Exception:\n",
        "        lang = \"\"\n",
        "\n",
        "    rows.append({\n",
        "        \"book_id\": slugify(f\"{series}_{p.stem}\"),\n",
        "        \"title\": title,\n",
        "        \"series\": series,\n",
        "        \"grade\": grade,\n",
        "        \"year\": \"\",         # можно заполнить позже, если нужно\n",
        "        \"txt_path\": str(p),\n",
        "        \"lang\": lang\n",
        "    })\n",
        "\n",
        "manifest = pd.DataFrame(rows).sort_values([\"series\", \"grade\", \"title\"])\n",
        "manifest_path = f\"{ROOT_DIR}/books_manifest.csv\"\n",
        "manifest.to_csv(manifest_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "display(manifest.head(20))\n",
        "print(\"Saved manifest ->\", manifest_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "znYLQaLACJvL",
        "outputId": "143d8098-8cf4-4c05-9174-cd771f302d64"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found txt files: 22\n",
            "Example: [PosixPath('/content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-10.txt'), PosixPath('/content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-2.txt'), PosixPath('/content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-3.txt')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    book_id         title     series  grade year  \\\n",
              "1     spotlight_spotlight_2   Spotlight 2  spotlight      2        \n",
              "2     spotlight_spotlight_3   Spotlight 3  spotlight      3        \n",
              "3     spotlight_spotlight_4   Spotlight 4  spotlight      4        \n",
              "4     spotlight_spotlight_5   Spotlight 5  spotlight      5        \n",
              "5     spotlight_spotlight_6   Spotlight 6  spotlight      6        \n",
              "6     spotlight_spotlight_7   Spotlight 7  spotlight      7        \n",
              "7     spotlight_spotlight_8   Spotlight 8  spotlight      8        \n",
              "8     spotlight_spotlight_9   Spotlight 9  spotlight      9        \n",
              "0    spotlight_spotlight_10  Spotlight 10  spotlight     10        \n",
              "10  starlight_starlight_2_1   Starlight 2  starlight      2        \n",
              "11  starlight_starlight_2_2   Starlight 2  starlight      2        \n",
              "12  starlight_starlight_3_1   Starlight 3  starlight      3        \n",
              "13  starlight_starlight_3_2   Starlight 3  starlight      3        \n",
              "14  starlight_starlight_4_1   Starlight 4  starlight      4        \n",
              "15  starlight_starlight_4_2   Starlight 4  starlight      4        \n",
              "16    starlight_starlight_5   Starlight 5  starlight      5        \n",
              "17    starlight_starlight_6   Starlight 6  starlight      6        \n",
              "18    starlight_starlight_7   Starlight 7  starlight      7        \n",
              "19    starlight_starlight_8   Starlight 8  starlight      8        \n",
              "20    starlight_starlight_9   Starlight 9  starlight      9        \n",
              "\n",
              "                                             txt_path   lang  \n",
              "1   /content/drive/MyDrive/EduText Analyzer/Учебни...  mixed  \n",
              "2   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "3   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "4   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "5   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "6   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "7   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "8   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "0   /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "10  /content/drive/MyDrive/EduText Analyzer/Учебни...  mixed  \n",
              "11  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "12  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "13  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "14  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "15  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "16  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "17  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "18  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "19  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  \n",
              "20  /content/drive/MyDrive/EduText Analyzer/Учебни...     en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d335c4b1-86c6-4ace-8c4f-a919876915fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>title</th>\n",
              "      <th>series</th>\n",
              "      <th>grade</th>\n",
              "      <th>year</th>\n",
              "      <th>txt_path</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spotlight_spotlight_2</td>\n",
              "      <td>Spotlight 2</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>mixed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spotlight_spotlight_3</td>\n",
              "      <td>Spotlight 3</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spotlight_spotlight_4</td>\n",
              "      <td>Spotlight 4</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spotlight_spotlight_5</td>\n",
              "      <td>Spotlight 5</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spotlight_spotlight_6</td>\n",
              "      <td>Spotlight 6</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>6</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>spotlight_spotlight_7</td>\n",
              "      <td>Spotlight 7</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>7</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>spotlight_spotlight_8</td>\n",
              "      <td>Spotlight 8</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>8</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spotlight_spotlight_9</td>\n",
              "      <td>Spotlight 9</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>9</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spotlight_spotlight_10</td>\n",
              "      <td>Spotlight 10</td>\n",
              "      <td>spotlight</td>\n",
              "      <td>10</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>starlight_starlight_2_1</td>\n",
              "      <td>Starlight 2</td>\n",
              "      <td>starlight</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>mixed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>starlight_starlight_2_2</td>\n",
              "      <td>Starlight 2</td>\n",
              "      <td>starlight</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>starlight_starlight_3_1</td>\n",
              "      <td>Starlight 3</td>\n",
              "      <td>starlight</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>starlight_starlight_3_2</td>\n",
              "      <td>Starlight 3</td>\n",
              "      <td>starlight</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>starlight_starlight_4_1</td>\n",
              "      <td>Starlight 4</td>\n",
              "      <td>starlight</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>starlight_starlight_4_2</td>\n",
              "      <td>Starlight 4</td>\n",
              "      <td>starlight</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>starlight_starlight_5</td>\n",
              "      <td>Starlight 5</td>\n",
              "      <td>starlight</td>\n",
              "      <td>5</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>starlight_starlight_6</td>\n",
              "      <td>Starlight 6</td>\n",
              "      <td>starlight</td>\n",
              "      <td>6</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>starlight_starlight_7</td>\n",
              "      <td>Starlight 7</td>\n",
              "      <td>starlight</td>\n",
              "      <td>7</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>starlight_starlight_8</td>\n",
              "      <td>Starlight 8</td>\n",
              "      <td>starlight</td>\n",
              "      <td>8</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>starlight_starlight_9</td>\n",
              "      <td>Starlight 9</td>\n",
              "      <td>starlight</td>\n",
              "      <td>9</td>\n",
              "      <td></td>\n",
              "      <td>/content/drive/MyDrive/EduText Analyzer/Учебни...</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d335c4b1-86c6-4ace-8c4f-a919876915fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d335c4b1-86c6-4ace-8c4f-a919876915fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d335c4b1-86c6-4ace-8c4f-a919876915fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-597a7799-33dd-4916-9ba8-54e786fc555a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-597a7799-33dd-4916-9ba8-54e786fc555a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-597a7799-33dd-4916-9ba8-54e786fc555a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Saved manifest ->\\\", manifest_path)\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"book_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"spotlight_spotlight_2\",\n          \"starlight_starlight_7\",\n          \"starlight_starlight_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Spotlight 2\",\n          \"Spotlight 3\",\n          \"Spotlight 7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"series\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"starlight\",\n          \"spotlight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          9,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"txt_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"/content/drive/MyDrive/EduText Analyzer/\\u0423\\u0447\\u0435\\u0431\\u043d\\u0438\\u043a\\u0438 TXT/spotlight-txt/spotlight-2.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved manifest -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/books_manifest.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL C — Catalog batch helpers + metrics + CEFR + Levenshtein\n",
        "# =========================\n",
        "\n",
        "!pip -q install textstat spacy python-Levenshtein deep-translator transliterate\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "\n",
        "import os, re, json, math, time, traceback\n",
        "from pathlib import Path\n",
        "from dataclasses import asdict\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import textstat\n",
        "import spacy\n",
        "\n",
        "import Levenshtein\n",
        "from transliterate import translit\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "CEFR_CSV_PATH = \"/content/drive/MyDrive/EduText Analyzer/Cefr/len_cefr.csv\"  # <-- поправь под свой путь\n",
        "ENABLE_CEFR = True\n",
        "ENABLE_LEV  = True   # если будет долго/лимиты — поставь False и посчитаешь позже отдельным прогоном\n",
        "LEV_TOP_K   = 2500   # как у тебя\n",
        "LEV_CACHE_PATH_DEFAULT = None  # зададим при batch-run через OUT_ROOT/cache/...\n",
        "\n",
        "# -------------------------\n",
        "# SAVE UTILS\n",
        "# -------------------------\n",
        "def ensure_dir(p: str):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def relpath(path: str, start: str) -> str:\n",
        "    try:\n",
        "        return os.path.relpath(path, start)\n",
        "    except Exception:\n",
        "        return path\n",
        "\n",
        "def save_table_bundle(df: pd.DataFrame, out_dir: str, name: str) -> Dict[str, str]:\n",
        "    ensure_dir(out_dir)\n",
        "    csv_path  = os.path.join(out_dir, f\"{name}.csv\")\n",
        "    xlsx_path = os.path.join(out_dir, f\"{name}.xlsx\")\n",
        "    html_path = os.path.join(out_dir, f\"{name}.html\")\n",
        "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
        "    df.to_excel(xlsx_path, index=False)\n",
        "    df.to_html(html_path, index=False)\n",
        "    return {\"csv\": csv_path, \"xlsx\": xlsx_path, \"html\": html_path}\n",
        "\n",
        "def save_plot(fig, out_dir: str, name: str) -> str:\n",
        "    ensure_dir(out_dir)\n",
        "    path = os.path.join(out_dir, f\"{name}.png\")\n",
        "    fig.savefig(path, dpi=200, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    return path\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# METRICS (by page / by module) — как в твоём CELL 2, только в функциях\n",
        "# -------------------------\n",
        "def tokenize_en(text: str) -> List[str]:\n",
        "    return re.findall(r\"[A-Za-z]+(?:'[A-Za-z]+)?\", (text or \"\").lower())\n",
        "\n",
        "def compute_ttr_family(tokens: List[str], segment_len: int = 100) -> Dict:\n",
        "    n = len(tokens)\n",
        "    if n == 0:\n",
        "        return {\"tokens\": 0, \"types\": 0, \"ttr\": np.nan, \"rttr\": np.nan, \"cttr\": np.nan, f\"msttr_{segment_len}\": np.nan}\n",
        "    types = len(set(tokens))\n",
        "    ttr  = types / n\n",
        "    rttr = types / math.sqrt(n)\n",
        "    cttr = types / math.sqrt(2 * n)\n",
        "\n",
        "    n_full = n // segment_len\n",
        "    if n_full > 0:\n",
        "        seg_ttrs = []\n",
        "        for i in range(n_full):\n",
        "            seg = tokens[i*segment_len:(i+1)*segment_len]\n",
        "            seg_ttrs.append(len(set(seg)) / segment_len)\n",
        "        msttr = float(np.mean(seg_ttrs))\n",
        "    else:\n",
        "        msttr = np.nan\n",
        "\n",
        "    return {\"tokens\": n, \"types\": types, \"ttr\": ttr, \"rttr\": rttr, \"cttr\": cttr, f\"msttr_{segment_len}\": msttr}\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return a / b if b else np.nan\n",
        "\n",
        "def compute_textstat_metrics(text: str) -> Dict:\n",
        "    text = text or \"\"\n",
        "    words = textstat.lexicon_count(text)\n",
        "    sents = textstat.sentence_count(text)\n",
        "    syll  = textstat.syllable_count(text)\n",
        "    return {\n",
        "        \"flesch_reading_ease\": textstat.flesch_reading_ease(text) if words else np.nan,\n",
        "        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(text) if words else np.nan,\n",
        "        \"words_total\": words,\n",
        "        \"sentences_total\": sents,\n",
        "        \"syllables_total\": syll,\n",
        "        \"avg_words_per_sentence\": safe_div(words, sents),\n",
        "    }\n",
        "\n",
        "def compute_metrics_for_text(text: str, segment_len: int = 100) -> Dict:\n",
        "    m = {}\n",
        "    m.update(compute_textstat_metrics(text))\n",
        "    tokens = tokenize_en(text)\n",
        "    m.update(compute_ttr_family(tokens, segment_len=segment_len))\n",
        "    return m\n",
        "\n",
        "def compute_metrics_df_by_page(pages, segment_len=100, min_tokens=50, min_words=50) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for p in pages:\n",
        "        m = compute_metrics_for_text(p.text_en, segment_len=segment_len)\n",
        "        rows.append({\"page_num\": p.page_num, \"module_id\": p.module_id, **m})\n",
        "    df = pd.DataFrame(rows).sort_values(\"page_num\")\n",
        "\n",
        "    df[\"is_sparse\"] = (df[\"tokens\"] < min_tokens) | (df[\"words_total\"] < min_words)\n",
        "\n",
        "    def sparse_reason(row):\n",
        "        reasons = []\n",
        "        if row[\"tokens\"] < min_tokens:\n",
        "            reasons.append(f\"tokens<{min_tokens}\")\n",
        "        if row[\"words_total\"] < min_words:\n",
        "            reasons.append(f\"words<{min_words}\")\n",
        "        return \", \".join(reasons) if reasons else \"\"\n",
        "\n",
        "    df[\"sparse_reason\"] = df.apply(sparse_reason, axis=1)\n",
        "    return df\n",
        "\n",
        "def compute_metrics_df_by_module(by_page: pd.DataFrame) -> pd.DataFrame:\n",
        "    # как ты делала: агрегируем по НЕ sparse страницам\n",
        "    return (\n",
        "        by_page[~by_page[\"is_sparse\"]]\n",
        "        .groupby(\"module_id\", dropna=False)\n",
        "        .mean(numeric_only=True)\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# CEFR\n",
        "# -------------------------\n",
        "CEFR_ORDER = {\"A1\": 1, \"A2\": 2, \"B1\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
        "\n",
        "def load_cefr_lexicon(csv_path: str, map_c1_to_b1: bool = True) -> Dict[str, str]:\n",
        "    # грузим csv; поддержим случай с ';'\n",
        "    with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "    if \";\" in content and \",\" not in content:\n",
        "        content = content.replace(\";\", \",\")\n",
        "    # читаем через pandas\n",
        "    from io import StringIO\n",
        "    df = pd.read_csv(StringIO(content))\n",
        "    # ожидаем колонки Word и CEFR Level\n",
        "    word_levels = {}\n",
        "    for _, row in df.iterrows():\n",
        "        w = str(row[\"Word\"]).strip().lower()\n",
        "        lvl = str(row[\"CEFR Level\"]).strip().upper()\n",
        "        if map_c1_to_b1 and lvl == \"C1\":\n",
        "            lvl = \"B1\"\n",
        "        if w in word_levels:\n",
        "            cur = word_levels[w]\n",
        "            if CEFR_ORDER.get(lvl, 99) < CEFR_ORDER.get(cur, 99):\n",
        "                word_levels[w] = lvl\n",
        "        else:\n",
        "            word_levels[w] = lvl\n",
        "    return word_levels\n",
        "\n",
        "def compute_cefr_tables(pages, word_levels: Dict[str, str], nlp) -> Tuple[pd.DataFrame, pd.DataFrame, Dict]:\n",
        "    \"\"\"\n",
        "    Возвращает:\n",
        "    - cefr_word_table: lemma, level, frequency, pos\n",
        "    - cefr_by_page: page_num + counts/percents по уровням\n",
        "    - cefr_summary: общий процент по токенам\n",
        "    \"\"\"\n",
        "    level_names = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
        "\n",
        "    lemma_freq = {}\n",
        "    lemma_pos_counts = {}  # lemma -> Counter(pos)\n",
        "    page_level_counts = []  # list of dicts per page\n",
        "    page_token_total = []\n",
        "\n",
        "    texts = [p.text_en or \"\" for p in pages]\n",
        "    # nlp.pipe быстрее\n",
        "    for p, doc in zip(pages, nlp.pipe(texts, batch_size=16)):\n",
        "        lvl_counter = dict.fromkeys(level_names, 0)\n",
        "        token_total = 0\n",
        "\n",
        "        for tok in doc:\n",
        "            if not tok.is_alpha or tok.is_stop:\n",
        "                continue\n",
        "            lemma = tok.lemma_.lower()\n",
        "            token_total += 1\n",
        "\n",
        "            # частоты лемм\n",
        "            lemma_freq[lemma] = lemma_freq.get(lemma, 0) + 1\n",
        "            # POS\n",
        "            if lemma not in lemma_pos_counts:\n",
        "                lemma_pos_counts[lemma] = {}\n",
        "            lemma_pos_counts[lemma][tok.pos_] = lemma_pos_counts[lemma].get(tok.pos_, 0) + 1\n",
        "\n",
        "            lvl = word_levels.get(lemma)\n",
        "            if lvl in lvl_counter:\n",
        "                lvl_counter[lvl] += 1\n",
        "\n",
        "        page_level_counts.append({\n",
        "            \"page_num\": p.page_num,\n",
        "            \"module_id\": p.module_id,\n",
        "            **{f\"tokens_{lvl}\": lvl_counter[lvl] for lvl in level_names},\n",
        "        })\n",
        "        page_token_total.append(token_total)\n",
        "\n",
        "    cefr_by_page = pd.DataFrame(page_level_counts).sort_values(\"page_num\")\n",
        "    cefr_by_page[\"tokens_total\"] = page_token_total\n",
        "\n",
        "    for lvl in level_names:\n",
        "        cefr_by_page[f\"pct_{lvl}\"] = cefr_by_page.apply(\n",
        "            lambda r: (r[f\"tokens_{lvl}\"] / r[\"tokens_total\"]) if r[\"tokens_total\"] else np.nan, axis=1\n",
        "        )\n",
        "\n",
        "    # word table\n",
        "    rows = []\n",
        "    for lemma, freq in lemma_freq.items():\n",
        "        lvl = word_levels.get(lemma)\n",
        "        if lvl not in CEFR_ORDER:\n",
        "            continue\n",
        "        # top pos\n",
        "        pos_counts = lemma_pos_counts.get(lemma, {})\n",
        "        if pos_counts:\n",
        "            pos = max(pos_counts.items(), key=lambda x: x[1])[0]\n",
        "        else:\n",
        "            pos = \"X\"\n",
        "        rows.append({\"word\": lemma, \"level\": lvl, \"frequency\": freq, \"pos\": pos})\n",
        "\n",
        "    cefr_word_table = pd.DataFrame(rows)\n",
        "    if not cefr_word_table.empty:\n",
        "        cefr_word_table[\"level_order\"] = cefr_word_table[\"level\"].map(CEFR_ORDER)\n",
        "        cefr_word_table = cefr_word_table.sort_values([\"level_order\", \"frequency\"], ascending=[True, False]).drop(columns=[\"level_order\"])\n",
        "\n",
        "    # summary by tokens\n",
        "    total_by_level = {lvl: int(cefr_by_page[f\"tokens_{lvl}\"].sum()) for lvl in level_names} if not cefr_by_page.empty else {lvl: 0 for lvl in level_names}\n",
        "    total_tokens = int(cefr_by_page[\"tokens_total\"].sum()) if not cefr_by_page.empty else 0\n",
        "    cefr_summary = {\n",
        "        \"tokens_total\": total_tokens,\n",
        "        \"by_level_tokens\": total_by_level,\n",
        "        \"by_level_pct\": {lvl: (total_by_level[lvl] / total_tokens) if total_tokens else None for lvl in level_names}\n",
        "    }\n",
        "\n",
        "    return cefr_word_table, cefr_by_page, cefr_summary\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# LEVENSHTEIN (формальное сходство) с кэшем переводов\n",
        "# -------------------------\n",
        "def transliterate_ru_to_en(word_ru: str) -> str:\n",
        "    try:\n",
        "        return translit(str(word_ru), \"ru\", reversed=True).lower()\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def load_translation_cache(cache_path: str) -> Dict[str, str]:\n",
        "    cache = {}\n",
        "    if cache_path and os.path.exists(cache_path):\n",
        "        try:\n",
        "            df = pd.read_csv(cache_path)\n",
        "            if {\"word\", \"translation_ru\"}.issubset(df.columns):\n",
        "                cache = dict(zip(df[\"word\"].astype(str), df[\"translation_ru\"].astype(str)))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return cache\n",
        "\n",
        "def save_translation_cache(cache: Dict[str, str], cache_path: str):\n",
        "    if not cache_path:\n",
        "        return\n",
        "    ensure_dir(os.path.dirname(cache_path))\n",
        "    df = pd.DataFrame({\"word\": list(cache.keys()), \"translation_ru\": list(cache.values())})\n",
        "    df.to_csv(cache_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "def compute_levenshtein_tables(pages, nlp, top_k: int, cache_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict]:\n",
        "    \"\"\"\n",
        "    Возвращает:\n",
        "    - lev_words: word, frequency, translation_ru, translation_en_translit, similarity\n",
        "    - lev_by_page: page_num, lev_mean_weighted, covered_tokens, total_tokens\n",
        "    - lev_by_module: module_id, lev_mean_weighted_mean\n",
        "    - lev_summary: общий mean\n",
        "    \"\"\"\n",
        "    # 1) соберём частоты лемм по страницам (EN слой)\n",
        "    page_lemma_counts = []\n",
        "    total_lemma_freq = {}\n",
        "\n",
        "    texts = [p.text_en or \"\" for p in pages]\n",
        "    for p, doc in zip(pages, nlp.pipe(texts, batch_size=16)):\n",
        "        c = {}\n",
        "        for tok in doc:\n",
        "            if not tok.is_alpha or tok.is_stop:\n",
        "                continue\n",
        "            lemma = tok.lemma_.lower()\n",
        "            c[lemma] = c.get(lemma, 0) + 1\n",
        "            total_lemma_freq[lemma] = total_lemma_freq.get(lemma, 0) + 1\n",
        "        page_lemma_counts.append((p.page_num, p.module_id, c))\n",
        "\n",
        "    # 2) top_k лемм для перевода\n",
        "    vocab_sorted = sorted(total_lemma_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    vocab = [w for w, _ in vocab_sorted[:top_k]]\n",
        "\n",
        "    # 3) кэш переводов\n",
        "    cache = load_translation_cache(cache_path)\n",
        "    translator = GoogleTranslator(source=\"en\", target=\"ru\")\n",
        "\n",
        "    missing = [w for w in vocab if w not in cache]\n",
        "    # ⚠️ это может быть долго и упираться в лимиты — кэш спасает\n",
        "    for i, w in enumerate(missing, start=1):\n",
        "        try:\n",
        "            cache[w] = translator.translate(w)\n",
        "        except Exception:\n",
        "            cache[w] = \"\"\n",
        "        if i % 50 == 0:\n",
        "            save_translation_cache(cache, cache_path)\n",
        "            # небольшой троттлинг\n",
        "            time.sleep(0.2)\n",
        "\n",
        "    save_translation_cache(cache, cache_path)\n",
        "\n",
        "    # 4) lev_words\n",
        "    rows = []\n",
        "    for w in vocab:\n",
        "        tr_ru = cache.get(w, \"\")\n",
        "        tr_en = transliterate_ru_to_en(tr_ru) if tr_ru else \"\"\n",
        "        sim = Levenshtein.ratio(w, tr_en) if tr_en else np.nan\n",
        "        rows.append({\"word\": w, \"frequency\": total_lemma_freq.get(w, 0), \"translation_ru\": tr_ru, \"translation_en_translit\": tr_en, \"similarity\": sim})\n",
        "    lev_words = pd.DataFrame(rows)\n",
        "\n",
        "    # 5) by_page weighted mean\n",
        "    sim_map = dict(zip(lev_words[\"word\"], lev_words[\"similarity\"]))\n",
        "\n",
        "    page_rows = []\n",
        "    for (page_num, module_id, c) in page_lemma_counts:\n",
        "        total_tokens = sum(c.values())\n",
        "        # берём только покрытые слова (у которых есть similarity)\n",
        "        w_sum = 0.0\n",
        "        w_den = 0.0\n",
        "        covered = 0\n",
        "\n",
        "        for w, f in c.items():\n",
        "            sim = sim_map.get(w, np.nan)\n",
        "            if sim is None or (isinstance(sim, float) and np.isnan(sim)):\n",
        "                continue\n",
        "            w_sum += sim * f\n",
        "            w_den += f\n",
        "            covered += f\n",
        "\n",
        "        mean_w = (w_sum / w_den) if w_den else np.nan\n",
        "        page_rows.append({\n",
        "            \"page_num\": page_num,\n",
        "            \"module_id\": module_id,\n",
        "            \"lev_mean_weighted\": mean_w,\n",
        "            \"covered_tokens\": covered,\n",
        "            \"total_tokens\": total_tokens,\n",
        "            \"coverage\": (covered / total_tokens) if total_tokens else np.nan\n",
        "        })\n",
        "\n",
        "    lev_by_page = pd.DataFrame(page_rows).sort_values(\"page_num\")\n",
        "\n",
        "    # 6) by_module (среднее по страницам)\n",
        "    lev_by_module = (\n",
        "        lev_by_page.groupby(\"module_id\", dropna=False)\n",
        "        .agg(lev_mean_weighted_mean=(\"lev_mean_weighted\", \"mean\"),\n",
        "             coverage_mean=(\"coverage\", \"mean\"))\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    lev_summary = {\n",
        "        \"lev_mean_weighted_overall\": float(np.nanmean(lev_by_page[\"lev_mean_weighted\"])) if not lev_by_page.empty else None,\n",
        "        \"coverage_mean_overall\": float(np.nanmean(lev_by_page[\"coverage\"])) if not lev_by_page.empty else None,\n",
        "        \"top_k\": top_k\n",
        "    }\n",
        "\n",
        "    return lev_words, lev_by_page, lev_by_module, lev_summary\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# PLOTS\n",
        "# -------------------------\n",
        "def plot_line(df: pd.DataFrame, x: str, y: str, title: str, xlabel: str, ylabel: str):\n",
        "    fig = plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df[x], df[y])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_cefr_distribution(cefr_summary: Dict):\n",
        "    levels = [\"A1\",\"A2\",\"B1\",\"B2\",\"C1\",\"C2\"]\n",
        "    vals = [cefr_summary[\"by_level_pct\"].get(lvl) or 0 for lvl in levels]\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "    plt.bar(levels, vals)\n",
        "    plt.title(\"CEFR distribution (by tokens)\")\n",
        "    plt.xlabel(\"Level\")\n",
        "    plt.ylabel(\"Share\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# ONE BOOK ANALYSIS\n",
        "# -------------------------\n",
        "def analyze_one_book(book_row: Dict, out_root: str, nlp, word_levels: Optional[Dict], lev_cache_path: Optional[str]) -> Dict:\n",
        "    book_id = book_row[\"book_id\"]\n",
        "    txt_path = book_row[\"txt_path\"]\n",
        "\n",
        "    book_dir   = os.path.join(out_root, \"books\", book_id)\n",
        "    tables_dir = os.path.join(book_dir, \"tables\")\n",
        "    plots_dir  = os.path.join(book_dir, \"plots\")\n",
        "    ensure_dir(tables_dir); ensure_dir(plots_dir)\n",
        "\n",
        "    # read text\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text_raw = f.read()\n",
        "\n",
        "    # preprocess (твой CELL 1 должен быть уже выполнен)\n",
        "    pages = preprocess_document(text_raw)\n",
        "\n",
        "    # metrics\n",
        "    by_page = compute_metrics_df_by_page(pages)\n",
        "    by_module = compute_metrics_df_by_module(by_page)\n",
        "\n",
        "    tables = {}\n",
        "    plots = {}\n",
        "    tables[\"metrics_by_page\"]   = save_table_bundle(by_page, tables_dir, \"metrics_by_page\")\n",
        "    tables[\"metrics_by_module\"] = save_table_bundle(by_module, tables_dir, \"metrics_by_module\")\n",
        "\n",
        "    # plots for metrics\n",
        "    if \"flesch_reading_ease\" in by_page.columns:\n",
        "        fig = plot_line(by_page.dropna(subset=[\"flesch_reading_ease\"]), \"page_num\", \"flesch_reading_ease\",\n",
        "                        \"Flesch Reading Ease by page\", \"Page\", \"Flesch Reading Ease\")\n",
        "        plots[\"flesch_reading_ease_by_page\"] = save_plot(fig, plots_dir, \"flesch_reading_ease_by_page\")\n",
        "\n",
        "    if \"flesch_kincaid_grade\" in by_page.columns:\n",
        "        fig = plot_line(by_page.dropna(subset=[\"flesch_kincaid_grade\"]), \"page_num\", \"flesch_kincaid_grade\",\n",
        "                        \"Flesch–Kincaid Grade by page\", \"Page\", \"FK Grade\")\n",
        "        plots[\"fk_grade_by_page\"] = save_plot(fig, plots_dir, \"fk_grade_by_page\")\n",
        "\n",
        "    if \"ttr\" in by_page.columns:\n",
        "        fig = plot_line(by_page.dropna(subset=[\"ttr\"]), \"page_num\", \"ttr\",\n",
        "                        \"TTR by page\", \"Page\", \"TTR\")\n",
        "        plots[\"ttr_by_page\"] = save_plot(fig, plots_dir, \"ttr_by_page\")\n",
        "\n",
        "    # CEFR\n",
        "    cefr_summary = None\n",
        "    if ENABLE_CEFR and word_levels is not None:\n",
        "        cefr_word_table, cefr_by_page, cefr_summary = compute_cefr_tables(pages, word_levels, nlp)\n",
        "        tables[\"cefr_word_table\"] = save_table_bundle(cefr_word_table, tables_dir, \"cefr_word_table\")\n",
        "        tables[\"cefr_by_page\"]    = save_table_bundle(cefr_by_page, tables_dir, \"cefr_by_page\")\n",
        "\n",
        "        # plot CEFR distribution\n",
        "        if cefr_summary:\n",
        "            fig = plot_cefr_distribution(cefr_summary)\n",
        "            plots[\"cefr_distribution\"] = save_plot(fig, plots_dir, \"cefr_distribution\")\n",
        "\n",
        "    # Levenshtein\n",
        "    lev_summary = None\n",
        "    if ENABLE_LEV and lev_cache_path:\n",
        "        lev_words, lev_by_page, lev_by_module, lev_summary = compute_levenshtein_tables(\n",
        "            pages, nlp, top_k=LEV_TOP_K, cache_path=lev_cache_path\n",
        "        )\n",
        "        tables[\"lev_words\"]     = save_table_bundle(lev_words, tables_dir, \"lev_words\")\n",
        "        tables[\"lev_by_page\"]   = save_table_bundle(lev_by_page, tables_dir, \"lev_by_page\")\n",
        "        tables[\"lev_by_module\"] = save_table_bundle(lev_by_module, tables_dir, \"lev_by_module\")\n",
        "\n",
        "        if \"lev_mean_weighted\" in lev_by_page.columns:\n",
        "            fig = plot_line(lev_by_page.dropna(subset=[\"lev_mean_weighted\"]), \"page_num\", \"lev_mean_weighted\",\n",
        "                            \"Levenshtein similarity (weighted) by page\", \"Page\", \"Mean similarity\")\n",
        "            plots[\"lev_mean_by_page\"] = save_plot(fig, plots_dir, \"lev_mean_by_page\")\n",
        "\n",
        "    # meta summary\n",
        "    means = {\n",
        "        \"flesch_reading_ease\": float(by_page[\"flesch_reading_ease\"].dropna().mean()) if \"flesch_reading_ease\" in by_page else None,\n",
        "        \"flesch_kincaid_grade\": float(by_page[\"flesch_kincaid_grade\"].dropna().mean()) if \"flesch_kincaid_grade\" in by_page else None,\n",
        "        \"ttr\": float(by_page[\"ttr\"].dropna().mean()) if \"ttr\" in by_page else None,\n",
        "        \"msttr_100\": float(by_page[\"msttr_100\"].dropna().mean()) if \"msttr_100\" in by_page else None,\n",
        "        \"lev_mean_weighted\": (lev_summary.get(\"lev_mean_weighted_overall\") if lev_summary else None),\n",
        "    }\n",
        "\n",
        "    meta = {\n",
        "        \"book_id\": book_id,\n",
        "        \"title\": book_row.get(\"title\"),\n",
        "        \"series\": book_row.get(\"series\"),\n",
        "        \"grade\": book_row.get(\"grade\"),\n",
        "        \"year\": book_row.get(\"year\"),\n",
        "        \"lang\": book_row.get(\"lang\"),\n",
        "        \"txt_path\": txt_path,\n",
        "        \"pages_total\": int(len(pages)),\n",
        "        \"means\": means,\n",
        "        \"cefr_summary\": cefr_summary,\n",
        "        \"lev_summary\": lev_summary,\n",
        "        \"artifacts\": {\n",
        "            \"tables\": {k: {kk: relpath(vv, out_root) for kk, vv in v.items()} for k, v in tables.items()},\n",
        "            \"plots\": {k: relpath(v, out_root) for k, v in plots.items()}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    meta_path = os.path.join(book_dir, \"meta.json\")\n",
        "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return meta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUh2aHgNDYo4",
        "outputId": "8a07c8ff-0a81-404c-b2d2-a10d7b6bbc5b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# CELL D — BATCH RUN (22 books) -> catalog_out\n",
        "# =========================\n",
        "\n",
        "MANIFEST_PATH = \"/content/drive/MyDrive/EduText Analyzer/Учебники TXT/books_manifest.csv\"\n",
        "OUT_ROOT      = \"/content/drive/MyDrive/EduText Analyzer/catalog_out\"\n",
        "\n",
        "ensure_dir(OUT_ROOT)\n",
        "\n",
        "# Levenshtein cache (общий на все книги)\n",
        "LEV_CACHE_PATH = os.path.join(OUT_ROOT, \"cache\", \"lev_translation_cache.csv\")\n",
        "ensure_dir(os.path.dirname(LEV_CACHE_PATH))\n",
        "\n",
        "# spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# CEFR lexicon\n",
        "word_levels = None\n",
        "if ENABLE_CEFR:\n",
        "    word_levels = load_cefr_lexicon(CEFR_CSV_PATH, map_c1_to_b1=True)\n",
        "    print(\"CEFR lexicon loaded:\", len(word_levels))\n",
        "\n",
        "manifest = pd.read_csv(MANIFEST_PATH).replace({np.nan: None})\n",
        "print(\"Books:\", len(manifest))\n",
        "\n",
        "index = []\n",
        "errors = []\n",
        "\n",
        "for i, row in enumerate(manifest.to_dict(\"records\"), start=1):\n",
        "    book_id = row.get(\"book_id\")\n",
        "    print(f\"\\n[{i}/{len(manifest)}] Processing: {book_id} -> {row.get('txt_path')}\")\n",
        "\n",
        "    try:\n",
        "        meta = analyze_one_book(\n",
        "            book_row=row,\n",
        "            out_root=OUT_ROOT,\n",
        "            nlp=nlp,\n",
        "            word_levels=word_levels,\n",
        "            lev_cache_path=LEV_CACHE_PATH if ENABLE_LEV else None\n",
        "        )\n",
        "        index.append(meta)\n",
        "        print(\"OK:\", book_id)\n",
        "    except Exception as e:\n",
        "        err = {\"book_id\": book_id, \"error\": str(e), \"traceback\": traceback.format_exc()}\n",
        "        errors.append(err)\n",
        "        print(\"FAILED:\", book_id, \"-\", e)\n",
        "\n",
        "# save index/errors\n",
        "index_path = os.path.join(OUT_ROOT, \"index.json\")\n",
        "errors_path = os.path.join(OUT_ROOT, \"errors.json\")\n",
        "\n",
        "with open(index_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(index, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(errors_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(errors, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nDONE\")\n",
        "print(\"index.json:\", index_path)\n",
        "print(\"errors.json:\", errors_path)\n",
        "print(\"OK:\", len(index), \"FAILED:\", len(errors))\n",
        "\n",
        "# ZIP для удобной выгрузки\n",
        "import shutil\n",
        "zip_path = os.path.join(os.path.dirname(OUT_ROOT), \"catalog_out.zip\")\n",
        "if os.path.exists(zip_path):\n",
        "    os.remove(zip_path)\n",
        "shutil.make_archive(base_name=zip_path.replace(\".zip\",\"\"), format=\"zip\", root_dir=OUT_ROOT)\n",
        "print(\"ZIP:\", zip_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1lvMHWLFBy2",
        "outputId": "03f948bb-f173-4955-bc60-3efc3ed9b14b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CEFR lexicon loaded: 7654\n",
            "Books: 22\n",
            "\n",
            "[1/22] Processing: spotlight_spotlight_2 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-2.txt\n",
            "OK: spotlight_spotlight_2\n",
            "\n",
            "[2/22] Processing: spotlight_spotlight_3 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-3.txt\n",
            "OK: spotlight_spotlight_3\n",
            "\n",
            "[3/22] Processing: spotlight_spotlight_4 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-4.txt\n",
            "OK: spotlight_spotlight_4\n",
            "\n",
            "[4/22] Processing: spotlight_spotlight_5 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-5.txt\n",
            "OK: spotlight_spotlight_5\n",
            "\n",
            "[5/22] Processing: spotlight_spotlight_6 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-6.txt\n",
            "OK: spotlight_spotlight_6\n",
            "\n",
            "[6/22] Processing: spotlight_spotlight_7 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-7.txt\n",
            "OK: spotlight_spotlight_7\n",
            "\n",
            "[7/22] Processing: spotlight_spotlight_8 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-8.txt\n",
            "OK: spotlight_spotlight_8\n",
            "\n",
            "[8/22] Processing: spotlight_spotlight_9 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-9.txt\n",
            "OK: spotlight_spotlight_9\n",
            "\n",
            "[9/22] Processing: spotlight_spotlight_10 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/spotlight-txt/spotlight-10.txt\n",
            "OK: spotlight_spotlight_10\n",
            "\n",
            "[10/22] Processing: starlight_starlight_2_1 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-2-1.txt\n",
            "OK: starlight_starlight_2_1\n",
            "\n",
            "[11/22] Processing: starlight_starlight_2_2 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-2-2.txt\n",
            "OK: starlight_starlight_2_2\n",
            "\n",
            "[12/22] Processing: starlight_starlight_3_1 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-3-1.txt\n",
            "OK: starlight_starlight_3_1\n",
            "\n",
            "[13/22] Processing: starlight_starlight_3_2 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-3-2.txt\n",
            "OK: starlight_starlight_3_2\n",
            "\n",
            "[14/22] Processing: starlight_starlight_4_1 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-4-1.txt\n",
            "OK: starlight_starlight_4_1\n",
            "\n",
            "[15/22] Processing: starlight_starlight_4_2 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-4-2.txt\n",
            "OK: starlight_starlight_4_2\n",
            "\n",
            "[16/22] Processing: starlight_starlight_5 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-5.txt\n",
            "OK: starlight_starlight_5\n",
            "\n",
            "[17/22] Processing: starlight_starlight_6 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-6.txt\n",
            "OK: starlight_starlight_6\n",
            "\n",
            "[18/22] Processing: starlight_starlight_7 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-7.txt\n",
            "OK: starlight_starlight_7\n",
            "\n",
            "[19/22] Processing: starlight_starlight_8 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-8.txt\n",
            "OK: starlight_starlight_8\n",
            "\n",
            "[20/22] Processing: starlight_starlight_9 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-9.txt\n",
            "OK: starlight_starlight_9\n",
            "\n",
            "[21/22] Processing: starlight_starlight_10 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight-10.txt\n",
            "OK: starlight_starlight_10\n",
            "\n",
            "[22/22] Processing: starlight_starlight11 -> /content/drive/MyDrive/EduText Analyzer/Учебники TXT/starlight-txt/starlight11.txt\n",
            "OK: starlight_starlight11\n",
            "\n",
            "DONE\n",
            "index.json: /content/drive/MyDrive/EduText Analyzer/catalog_out/index.json\n",
            "errors.json: /content/drive/MyDrive/EduText Analyzer/catalog_out/errors.json\n",
            "OK: 22 FAILED: 0\n",
            "ZIP: /content/drive/MyDrive/EduText Analyzer/catalog_out.zip\n"
          ]
        }
      ]
    }
  ]
}